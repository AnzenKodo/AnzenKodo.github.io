<!DOCTYPE html>
<html lang="en">
	<head>
		<title>AI & DS 2 - AK#Notes</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
  		<meta name="author" content="AnzenKodo">
		<meta name="theme-color" content="#FF6C22">
		<meta name="description" content="# Numerical  ## Illustrate inferencing in Bayesian Belief Network with an example. (2023 Dec) (2022)">
		<meta property="og:description" content="# Numerical  ## Illustrate inferencing in Bayesian Belief Network with an example. (2023 Dec) (2022)">
		<meta property="og:image" content="https://AnzenKodo.github.io/assets/favicon/notes.png">
  		<meta property="og:image:alt" content="AK#Notes logo">
  		<meta property="og:site_name" content="AK#Notes">
		<meta property="og:title" content="AI & DS 2 - AK#Notes">
		<meta property="og:url" content="https://AnzenKodo.github.io/notes/notes/Collage/Sem7/Sem/AI & DS 2.html">
		<meta property="og:type" content="article">
		<meta property="og:article:author" content="AnzenKodo">
		<link rel="icon" type="image/png" href="https://AnzenKodo.github.io/assets/favicon/notes.png">
		<style>
			*,::after,::before{box-sizing:border-box}html{font-family:ui-serif, serif;line-height:1.15;-webkit-text-size-adjust:100%;-moz-tab-size:4;tab-size:4}body{margin:0}hr{height:0;color:inherit}abbr[title]{text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,pre,samp{font-family:ui-monospace,SFMono-Regular,Consolas,'Liberation Mono',Menlo,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}table{text-indent:0;border-color:inherit}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}::-moz-focus-inner{border-style:none;padding:0}:-moz-focusring{outline:1px dotted ButtonText}:-moz-ui-invalid{box-shadow:none}legend{padding:0}progress{vertical-align:baseline}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}summary{display:list-item}

            :root {
                color-scheme: dark light;
                --theme: #FF6C22;
			}
			body {
                max-width: 40rem;
                margin: 0 auto;
                font-family: system-ui;
                padding: 0 1em;
                color: inherit !important;
                word-break: break-word;
			}
			h1, h2, h3, h4, h5, h6 {
                font-family: monospace;
                margin: 2rem 0 0.5rem 0;
			}
			h2 {
                font-size: 2rem;
			}
			h3 {
			    font-size: 1.8rem;
			}
			h4 {
			    font-size: 1.5rem;
			}
			h5 {
			    font-size: 1.3rem;
			}
			h6 {
			    font-size: 1rem;
			}
			p, li, td, code {
			    line-height: 1.5rem;
			}
			a {
			    color: var(--theme);
			    text-decoration: none;
			}
			a:hover, a:focus {
			    text-decoration: underline;
			}
			a:active {
			    background: var(--theme);
			    color: inherit;
			}
			ul ul, ul ol, ol ol, ol ul {
                margin-top: .5rem;
			}
			li {
                margin-bottom: .5rem;
			}
			table {
			    border-collapse: collapse;
                overflow-x: auto;
                display: block;
                word-break: auto-phrase;
                margin: 1rem 0;
			}
            th {
                font-size: 1.1rem;
                border: 2px solid;
                padding: .3rem .3rem;
            }
            td {
                border: 1px solid;
                padding: .3rem .5rem;
            }
            blockquote {
                margin-left: 0;
                margin-right: 0;
                border: 1px solid;
                border-left: 10px solid;
                padding: 0 1rem;
            }
            .code-block {
                background: black;
                overflow-x: auto;
                padding: 0em 1em;
                border: 1px solid;
            }
            .code-block-language-name {
                position: sticky;
                left: 95%;
                top: .5em;
                font-weight: bold;
                color: white;
            }
            :not(pre.chroma) > code {
                border: 1px solid;
                padding: .3rem .2rem .2rem .2rem;
            }
            img {
                max-width: 100%;
                display: block;
                margin: 0 auto;
            }
            [href="#skip-top-main"] {
                padding: 0.3em;
                position: absolute;
                transform: translateY(-200%);
            }
            [href="#skip-top-main"]:focus {
                transform: translateY(0%);
                background: var(--theme);
                color: inherit;
            }
            #table-of-content {
                position: fixed;
                bottom: 10px;
                right: 10px;
                background: black;
                padding: 0.5rem 1em;
                z-index: 1;
                color: white;
            }
            #table-of-content[open] {
                max-height: 90%;
                overflow-y: auto;
                bottom: 50px;
                margin-left: 1em;
            }
            #table-of-content[open] summary {
                background: black;
                padding: 0.5em 1em;
                text-align: center;
                position: fixed;
                bottom: 10px;
                right: 10px;
            }
            #table-of-content ul:first-child {
                padding-left: 1em;
                margin-top: 1.5em;
            }
            .heading-anchor::before {
                content: "#";
                margin-right: .5rem;
            }
            .mermaid {
                background: black;
                border: 1px solid;
                margin-top: 1rem;
                padding: 1rem;
                font-family: monospace;
            }
            .mermaid svg {
                display: block;
                margin: auto;
            }
            .mermaid:has(svg) {
                background: none;
                border: none;
                margin-top: 1rem;
                padding: 0;
            }
            mjx-container {
                display: math;
                overflow-y: hidden;
                overflow-x: auto;
                max-width: 100%;
                padding-bottom: .8rem;
            }
            iframe {
                width: 100%;
                height: 21rem;
                margin: 1rem 0;
            }
		</style>
	</head>
	<body>
	    <a href="#skip-top-main">Skip to main</a>
	    <img id="audio-img" src="https://i.imgur.com/nle7lDV.png" style="
	          position: absolute;
	          top: -1rem;
	          right: 5%;
	          transform: scale(-1, 1);
	          opacity: 0.8;
	          height: 30rem;
	         ">
	    <audio>
	        <source src="https://anzenkodo.github.io/drive/cosmic.mp3" />
	    </audio>
		<header>
			<h1 style="text-align: center;">
                <a href="https://AnzenKodo.github.io">AK</a>#<a href="https://AnzenKodo.github.io/notes">Notes</a>
            </h1>
            <!-- <img src="https://AnzenKodo.github.io/assets/driftnet.png" alt="DriftNet Sponsored Image" style="margin: 1rem 0 1.5rem 0;"> -->
		</header>
		<main id="skip-top-main">
			<h1 style="font-size: 2.3rem; margin-top: 0;">AI & DS 2</h1>
			<h1><a name="numerical" class="heading-anchor" href="#numerical" rel="nofollow" aria-hidden="true"></a>Numerical</h1><h2><a name="illustrate-inferencing-in-bayesian-belief-network-with-an-example-2023-dec-2022" class="heading-anchor" href="#illustrate-inferencing-in-bayesian-belief-network-with-an-example-2023-dec-2022" rel="nofollow" aria-hidden="true"></a>Illustrate inferencing in Bayesian Belief Network with an example. (2023 Dec) (2022)</h2>
<iframe src="https://www.youtube.com/embed/DVnubVOjZtg" title="Bayesian Network with Examples | Easiest Explanation" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

<pre class='mermaid'>flowchart RL
	A([Rain])-->B
	A-->C
	B([Sprinkler])-->C([Grass Wet])
</pre>
<p>Rain:</p>

<table>
<thead>
<tr>
<th>Rain</th>
<th>Not Rain</th>
</tr>
</thead>

<tbody>
<tr>
<td>0.2</td>
<td>0.8</td>
</tr>
</tbody>
</table>

<p>Sprinkler:</p>

<table>
<thead>
<tr>
<th>Rain</th>
<th>Sprinkler</th>
</tr>
</thead>

<tbody>
<tr>
<td>False</td>
<td>0.4</td>
</tr>

<tr>
<td>True</td>
<td>0.01</td>
</tr>
</tbody>
</table>

<p>Grass Wet:</p>

<table>
<thead>
<tr>
<th>Sprinkler</th>
<th>Rain</th>
<th>Grass Wet</th>
</tr>
</thead>

<tbody>
<tr>
<td>False</td>
<td>False</td>
<td>0.0</td>
</tr>

<tr>
<td>False</td>
<td>True</td>
<td>0.8</td>
</tr>

<tr>
<td>True</td>
<td>False</td>
<td>0.9</td>
</tr>

<tr>
<td>True</td>
<td>True</td>
<td>0.99</td>
</tr>
</tbody>
</table>

<p><strong>Formula:</strong></p>

<p>$$P(A|B) = {P(A\cap B) \over P(B)}$$</p>

<p>$$A\cap B= P(A|B) \times P(B)$$</p>

<p><strong>Solutions:</strong></p>

<p>$$P(\text{Grass Wet, Spinkler, Rain}) = P(\text{Grass Wet | Spinkler, Rain}) \times P(\text{Spinkler | Rain}) \times P(\text{Rain})$$</p>

<p>$$= 0.99 \times 0.01 \times 0.2$$</p>
<h2><a name="find-p-cavity-toothache-from-the-given-probability-distribution-2023-dec-2022-5-marks" class="heading-anchor" href="#find-p-cavity-toothache-from-the-given-probability-distribution-2023-dec-2022-5-marks" rel="nofollow" aria-hidden="true"></a>Find P (¬ Cavity | Toothache) from the given probability distribution. (2023 Dec) (2022) 5 Marks</h2>
<table> <tr> <th rowspan="2"></th> <th colspan="2">Toothache</th> <th colspan="2">¬ Toothache</th> </tr> <tr> <th>Catch</th> <th>¬ Catch</th> <th>Catch</th> <th>¬ Catch</th> </tr> <tr> <th>Cavity</th> <td>0.108</td> <td>0.012</td> <td>0.072</td> <td>0.008</td> </tr> <tr> <th>¬ Cavity</th> <td>0.016</td> <td>0.064</td> <td>0.144</td> <td>0.576</td> </tr> </table>

<iframe src="https://www.youtube.com/embed/ULk_2eTXCzM" title="Toothache and Cavity Solution NTA NET Computer Science Part -I" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

<ul>
<li>$P(Cavity) = 0.108 + 0.12 + 0.072 + 0.008 = 0.308$</li>
<li>$P(¬Cavity) = 0.16 + 0.064 + 0.144 + 0.576 = 0.944$</li>
<li>$P(Toothache) = 0.108 + 0.012 + 0.016 + 0.064 =$</li>
<li>$P(¬Toothache) = 0.072 + 0.008 + 0.144 + 0.576 = 0.8$</li>
</ul>

<p>$$P(A\cup B)=P(A)\cup P(B)-P(A\cup B)$$</p>

<p>$$P(Cavity \cup Toothache)=P(Cavity)\cup P(Toothache)¬ P(Cavity\cap Toothache) = 0.2+0.2-(0.108 + 0.12) = 0.172$$</p>

<p>Bayes Theorem Formula:</p>

<p>$$P(A|B)= {P(A∩B)\over P(B)}$$</p>

<ul>
<li>$P(Cavity|Toothache)$ = ${P(Cavity \cap Toothache) \over P(Toothache)} = {0.108 + 12 \over 0.2}$</li>
<li>$P(Cavity|Toothache \wedge Catch) = {P(Cavity \cap (Toothache \cup Catch) \over P(Toothache \cup Cavity}) = {0.108 +0.012+0.072 \over 0.172}$</li>
</ul>
<h2><a name="calculate-accuracy-precision-recall-sensitivity-and-specificity-for-the-given-confusion-matrix-2023-dec-2022-2024" class="heading-anchor" href="#calculate-accuracy-precision-recall-sensitivity-and-specificity-for-the-given-confusion-matrix-2023-dec-2022-2024" rel="nofollow" aria-hidden="true"></a>Calculate Accuracy, Precision, Recall, Sensitivity and Specificity for the given confusion matrix (2023 Dec) (2022) (2024)</h2>
<p><img loading="lazy" src="assets/Pasted%20image%2020241030210252.png" alt="" /></p>

<p><img loading="lazy" src="assets/Pasted%20image%2020241102181142.png" alt="" /></p>

<p>Accuracy:</p>

<p>$${TP+TN \over Total} = {6954 + 2588 \over 10000} = 0.9532 = 95.32\%$$</p>

<p>Recall:</p>

<p>$${TP \over TP + FN} = {6954 \over 6954 + 412} = 0.9440 = 94.40\%$$</p>

<p>Specificity</p>

<p>$${TN \over N} = {2588 \over 3000} = 0.8626 = 86.26\%$$</p>

<p>Precision</p>

<p>$${TP \over TP + FP} = {6954 \over 6954 + 46} = 0.9934 = 99.34\%$$</p>

<p>F1 Score</p>

<p>$$
{2 \times Precision \times Recall \over Precesion + Recall} =
{2 \times 0.9934 \times 0.9440 \over 0.9934 + 0.9440} =
= 0.9680 = 96.80\%
$$</p>
<h2><a name="implement-and-and-not-and-xor-function-using-mcculloch-pitts-neuron-2023-may-2023-dec-5-marks" class="heading-anchor" href="#implement-and-and-not-and-xor-function-using-mcculloch-pitts-neuron-2023-may-2023-dec-5-marks" rel="nofollow" aria-hidden="true"></a>Implement AND, AND NOT and XOR function using McCulloch-Pitts neuron.  (2023 May) (2023 Dec 5 Marks)</h2>
<iframe src="https://www.youtube.com/embed/zcusbLaYj7Y" title="6. Implement XOR function using McCulloch–Pitts neuron Soft Computing Machine Learning Mahesh Huddar" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

<p><strong>AND</strong></p>

<p><strong>Step. 1)</strong> Construct a truth table for AND</p>

<table>
<thead>
<tr>
<th>X1</th>
<th>X2</th>
<th>Y</th>
</tr>
</thead>

<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>

<tr>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>

<tr>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>

<tr>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>Assume the weights are initialized to W1 = W2 = 1</p>

<p>Calculate the net input:</p>

<table>
<thead>
<tr>
<th>$X_1X_2 =$</th>
<th>$X_1W_1 +$</th>
<th>$X_2W_2$</th>
<th>= $Ans$</th>
</tr>
</thead>

<tbody>
<tr>
<td>(0, 0)</td>
<td>0 x 1</td>
<td>0 x 1</td>
<td>0</td>
</tr>

<tr>
<td>(0, 1)</td>
<td>0 x 1</td>
<td>1 x 1</td>
<td>1</td>
</tr>

<tr>
<td>(1, 0)</td>
<td>1 x 1</td>
<td>0 x 1</td>
<td>1</td>
</tr>

<tr>
<td>(1, 1)</td>
<td>1 x 1</td>
<td>1 x 1</td>
<td>2</td>
</tr>
</tbody>
</table>

<p><strong>Step 2)</strong> Where,</p>

<ul>
<li>n = number of Input</li>
<li>w = positive Input weight</li>

<li><p>p = negative Input weight</p>

<div class="code-block"><html>
<style type="text/css">
/* Background */ .bg { color: #282c34 }
/* PreWrapper */ .chroma { color: #c9c9c9color: #282c34; }
/* Other */ .chroma .x { color: #c9c9c9 }
/* Error */ .chroma .err { color: #cf5967 }
/* CodeLine */ .chroma .cl { color: #c9c9c9 }
/* LineTableTD */ .chroma .lntd { vertical-align: top; padding: 0; margin: 0; border: 0;color: #c9c9c9 }
/* LineTable */ .chroma .lntable { border-spacing: 0; padding: 0; margin: 0; border: 0;color: #c9c9c9 }
/* LineHighlight */ .chroma .hl { color: #c9c9c9; background-color: #e5e5e5 }
/* LineNumbersTable */ .chroma .lnt { white-space: pre; user-select: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #939599 }
/* LineNumbers */ .chroma .ln { white-space: pre; user-select: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #939599 }
/* Line */ .chroma .line { display: flex;color: #c9c9c9 }
/* Keyword */ .chroma .k { color: #7fbaf5 }
/* KeywordConstant */ .chroma .kc { color: #cf5967; background-color: #43454f }
/* KeywordDeclaration */ .chroma .kd { color: #7fbaf5 }
/* KeywordNamespace */ .chroma .kn { color: #bc74c4 }
/* KeywordPseudo */ .chroma .kp { color: #bc74c4 }
/* KeywordReserved */ .chroma .kr { color: #7fbaf5 }
/* KeywordType */ .chroma .kt { color: #57c7ff; font-weight: bold }
/* Name */ .chroma .n { color: #c9c9c9 }
/* NameAttribute */ .chroma .na { color: #bc74c4 }
/* NameBuiltin */ .chroma .nb { color: #7fbaf5 }
/* NameBuiltinPseudo */ .chroma .bp { color: #7fbaf5 }
/* NameClass */ .chroma .nc { color: #ecbe7b }
/* NameConstant */ .chroma .no { color: #ecbe7b }
/* NameDecorator */ .chroma .nd { color: #ecbe7b }
/* NameEntity */ .chroma .ni { color: #c9c9c9 }
/* NameException */ .chroma .ne { color: #cf5967 }
/* NameFunction */ .chroma .nf { color: #57c7ff }
/* NameFunctionMagic */ .chroma .fm { color: #c9c9c9 }
/* NameLabel */ .chroma .nl { color: #cf5967 }
/* NameNamespace */ .chroma .nn { color: #c9c9c9 }
/* NameOther */ .chroma .nx { color: #c9c9c9 }
/* NameProperty */ .chroma .py { color: #c9c9c9 }
/* NameTag */ .chroma .nt { color: #bc74c4 }
/* NameVariable */ .chroma .nv { color: #bc74c4; font-style: italic }
/* NameVariableClass */ .chroma .vc { color: #57c7ff; font-weight: bold }
/* NameVariableGlobal */ .chroma .vg { color: #ecbe7b }
/* NameVariableInstance */ .chroma .vi { color: #57c7ff }
/* NameVariableMagic */ .chroma .vm { color: #c9c9c9 }
/* Literal */ .chroma .l { color: #c9c9c9 }
/* LiteralDate */ .chroma .ld { color: #57c7ff }
/* LiteralString */ .chroma .s { color: #82cc6a }
/* LiteralStringAffix */ .chroma .sa { color: #82cc6a }
/* LiteralStringBacktick */ .chroma .sb { color: #57c7ff }
/* LiteralStringChar */ .chroma .sc { color: #57c7ff }
/* LiteralStringDelimiter */ .chroma .dl { color: #82cc6a }
/* LiteralStringDoc */ .chroma .sd { color: #82cc6a }
/* LiteralStringDouble */ .chroma .s2 { color: #82cc6a }
/* LiteralStringEscape */ .chroma .se { color: #56b6c2 }
/* LiteralStringHeredoc */ .chroma .sh { color: #56b6c2 }
/* LiteralStringInterpol */ .chroma .si { color: #82cc6a }
/* LiteralStringOther */ .chroma .sx { color: #82cc6a }
/* LiteralStringRegex */ .chroma .sr { color: #57c7ff }
/* LiteralStringSingle */ .chroma .s1 { color: #82cc6a }
/* LiteralStringSymbol */ .chroma .ss { color: #82cc6a }
/* LiteralNumber */ .chroma .m { color: #56b6c2 }
/* LiteralNumberBin */ .chroma .mb { color: #57c7ff }
/* LiteralNumberFloat */ .chroma .mf { color: #56b6c2 }
/* LiteralNumberHex */ .chroma .mh { color: #57c7ff }
/* LiteralNumberInteger */ .chroma .mi { color: #56b6c2 }
/* LiteralNumberIntegerLong */ .chroma .il { color: #56b6c2 }
/* LiteralNumberOct */ .chroma .mo { color: #57c7ff }
/* Operator */ .chroma .o { color: #bc74c4 }
/* OperatorWord */ .chroma .ow { color: #bc74c4 }
/* Punctuation */ .chroma .p { color: #56b6c2 }
/* Comment */ .chroma .c { color: #3e4460 }
/* CommentHashbang */ .chroma .ch { color: #3e4460; font-style: italic }
/* CommentMultiline */ .chroma .cm { color: #3e4460 }
/* CommentSingle */ .chroma .c1 { color: #3e4460 }
/* CommentSpecial */ .chroma .cs { color: #bc74c4; font-style: italic }
/* CommentPreproc */ .chroma .cp { color: #7fbaf5 }
/* CommentPreprocFile */ .chroma .cpf { color: #7fbaf5 }
/* Generic */ .chroma .g { color: #c9c9c9 }
/* GenericDeleted */ .chroma .gd { color: #cf5967 }
/* GenericEmph */ .chroma .ge { color: #c9c9c9; text-decoration: underline }
/* GenericError */ .chroma .gr { color: #cf5967; font-weight: bold }
/* GenericHeading */ .chroma .gh { color: #ecbe7b; font-weight: bold }
/* GenericInserted */ .chroma .gi { color: #ecbe7b }
/* GenericOutput */ .chroma .go { color: #43454f }
/* GenericPrompt */ .chroma .gp { color: #c9c9c9 }
/* GenericStrong */ .chroma .gs { color: #cf5967; font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #cf5967; font-style: italic }
/* GenericTraceback */ .chroma .gt { color: #c9c9c9 }
/* GenericUnderline */ .chroma .gl { color: #c9c9c9; text-decoration: underline }
/* TextWhitespace */ .chroma .w { color: #c9c9c9 }
body { color: #282c34; }
</style><body class="bg">
<pre tabindex="0" class="chroma"><code><span class="line"><span class="cl">0 &gt;= nw - p
</span></span><span class="line"><span class="cl">2 &gt;= 2(1) - p
</span></span><span class="line"><span class="cl">2 &gt;= 2
</span></span></code></pre>
</body>
</html>
</div></li>
</ul>

<p><strong>AND NOT</strong></p>

<p><strong>Step. 1)</strong> Construct a truth table for AND NOT</p>

<table>
<thead>
<tr>
<th>X1</th>
<th>X2</th>
<th>Y</th>
</tr>
</thead>

<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>

<tr>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>

<tr>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>

<tr>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>Assume the weights are initialized to W1 = W2 = 1</p>

<p>Calculate the net input:</p>

<table>
<thead>
<tr>
<th>$X_1X_2 =$</th>
<th>$X_1W_1 +$</th>
<th>$X_2W_2$</th>
<th>= $Ans$</th>
</tr>
</thead>

<tbody>
<tr>
<td>(0, 0)</td>
<td>0 x 1</td>
<td>0 x 1</td>
<td>0</td>
</tr>

<tr>
<td>(0, 1)</td>
<td>0 x 1</td>
<td>1 x 1</td>
<td>1</td>
</tr>

<tr>
<td>(1, 0)</td>
<td>1 x 1</td>
<td>0 x 1</td>
<td>1</td>
</tr>

<tr>
<td>(1, 1)</td>
<td>1 x 1</td>
<td>1 x 1</td>
<td>2</td>
</tr>
</tbody>
</table>

<p>Assume the weights are initialized to W1 = 1,  W2 = -1</p>

<p>Calculate the net input:</p>

<table>
<thead>
<tr>
<th>$X_1X_2 =$</th>
<th>$X_1W_1 +$</th>
<th>$X_2W_2$</th>
<th>= $Ans$</th>
</tr>
</thead>

<tbody>
<tr>
<td>(0, 0)</td>
<td>0 x 1</td>
<td>0 x -1</td>
<td>0</td>
</tr>

<tr>
<td>(0, 1)</td>
<td>0 x 1</td>
<td>1 x -1</td>
<td>-1</td>
</tr>

<tr>
<td>(1, 0)</td>
<td>1 x 1</td>
<td>0 x -1</td>
<td>1</td>
</tr>

<tr>
<td>(1, 1)</td>
<td>1 x 1</td>
<td>1 x -1</td>
<td>0</td>
</tr>
</tbody>
</table>

<p><strong>Step 2)</strong> Where,</p>

<ul>
<li>n = number of Input</li>
<li>w = positive Input weight</li>

<li><p>p = negative Input weight</p>

<div class="code-block"><html>
<style type="text/css">
/* Background */ .bg { color: #282c34 }
/* PreWrapper */ .chroma { color: #c9c9c9color: #282c34; }
/* Other */ .chroma .x { color: #c9c9c9 }
/* Error */ .chroma .err { color: #cf5967 }
/* CodeLine */ .chroma .cl { color: #c9c9c9 }
/* LineTableTD */ .chroma .lntd { vertical-align: top; padding: 0; margin: 0; border: 0;color: #c9c9c9 }
/* LineTable */ .chroma .lntable { border-spacing: 0; padding: 0; margin: 0; border: 0;color: #c9c9c9 }
/* LineHighlight */ .chroma .hl { color: #c9c9c9; background-color: #e5e5e5 }
/* LineNumbersTable */ .chroma .lnt { white-space: pre; user-select: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #939599 }
/* LineNumbers */ .chroma .ln { white-space: pre; user-select: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #939599 }
/* Line */ .chroma .line { display: flex;color: #c9c9c9 }
/* Keyword */ .chroma .k { color: #7fbaf5 }
/* KeywordConstant */ .chroma .kc { color: #cf5967; background-color: #43454f }
/* KeywordDeclaration */ .chroma .kd { color: #7fbaf5 }
/* KeywordNamespace */ .chroma .kn { color: #bc74c4 }
/* KeywordPseudo */ .chroma .kp { color: #bc74c4 }
/* KeywordReserved */ .chroma .kr { color: #7fbaf5 }
/* KeywordType */ .chroma .kt { color: #57c7ff; font-weight: bold }
/* Name */ .chroma .n { color: #c9c9c9 }
/* NameAttribute */ .chroma .na { color: #bc74c4 }
/* NameBuiltin */ .chroma .nb { color: #7fbaf5 }
/* NameBuiltinPseudo */ .chroma .bp { color: #7fbaf5 }
/* NameClass */ .chroma .nc { color: #ecbe7b }
/* NameConstant */ .chroma .no { color: #ecbe7b }
/* NameDecorator */ .chroma .nd { color: #ecbe7b }
/* NameEntity */ .chroma .ni { color: #c9c9c9 }
/* NameException */ .chroma .ne { color: #cf5967 }
/* NameFunction */ .chroma .nf { color: #57c7ff }
/* NameFunctionMagic */ .chroma .fm { color: #c9c9c9 }
/* NameLabel */ .chroma .nl { color: #cf5967 }
/* NameNamespace */ .chroma .nn { color: #c9c9c9 }
/* NameOther */ .chroma .nx { color: #c9c9c9 }
/* NameProperty */ .chroma .py { color: #c9c9c9 }
/* NameTag */ .chroma .nt { color: #bc74c4 }
/* NameVariable */ .chroma .nv { color: #bc74c4; font-style: italic }
/* NameVariableClass */ .chroma .vc { color: #57c7ff; font-weight: bold }
/* NameVariableGlobal */ .chroma .vg { color: #ecbe7b }
/* NameVariableInstance */ .chroma .vi { color: #57c7ff }
/* NameVariableMagic */ .chroma .vm { color: #c9c9c9 }
/* Literal */ .chroma .l { color: #c9c9c9 }
/* LiteralDate */ .chroma .ld { color: #57c7ff }
/* LiteralString */ .chroma .s { color: #82cc6a }
/* LiteralStringAffix */ .chroma .sa { color: #82cc6a }
/* LiteralStringBacktick */ .chroma .sb { color: #57c7ff }
/* LiteralStringChar */ .chroma .sc { color: #57c7ff }
/* LiteralStringDelimiter */ .chroma .dl { color: #82cc6a }
/* LiteralStringDoc */ .chroma .sd { color: #82cc6a }
/* LiteralStringDouble */ .chroma .s2 { color: #82cc6a }
/* LiteralStringEscape */ .chroma .se { color: #56b6c2 }
/* LiteralStringHeredoc */ .chroma .sh { color: #56b6c2 }
/* LiteralStringInterpol */ .chroma .si { color: #82cc6a }
/* LiteralStringOther */ .chroma .sx { color: #82cc6a }
/* LiteralStringRegex */ .chroma .sr { color: #57c7ff }
/* LiteralStringSingle */ .chroma .s1 { color: #82cc6a }
/* LiteralStringSymbol */ .chroma .ss { color: #82cc6a }
/* LiteralNumber */ .chroma .m { color: #56b6c2 }
/* LiteralNumberBin */ .chroma .mb { color: #57c7ff }
/* LiteralNumberFloat */ .chroma .mf { color: #56b6c2 }
/* LiteralNumberHex */ .chroma .mh { color: #57c7ff }
/* LiteralNumberInteger */ .chroma .mi { color: #56b6c2 }
/* LiteralNumberIntegerLong */ .chroma .il { color: #56b6c2 }
/* LiteralNumberOct */ .chroma .mo { color: #57c7ff }
/* Operator */ .chroma .o { color: #bc74c4 }
/* OperatorWord */ .chroma .ow { color: #bc74c4 }
/* Punctuation */ .chroma .p { color: #56b6c2 }
/* Comment */ .chroma .c { color: #3e4460 }
/* CommentHashbang */ .chroma .ch { color: #3e4460; font-style: italic }
/* CommentMultiline */ .chroma .cm { color: #3e4460 }
/* CommentSingle */ .chroma .c1 { color: #3e4460 }
/* CommentSpecial */ .chroma .cs { color: #bc74c4; font-style: italic }
/* CommentPreproc */ .chroma .cp { color: #7fbaf5 }
/* CommentPreprocFile */ .chroma .cpf { color: #7fbaf5 }
/* Generic */ .chroma .g { color: #c9c9c9 }
/* GenericDeleted */ .chroma .gd { color: #cf5967 }
/* GenericEmph */ .chroma .ge { color: #c9c9c9; text-decoration: underline }
/* GenericError */ .chroma .gr { color: #cf5967; font-weight: bold }
/* GenericHeading */ .chroma .gh { color: #ecbe7b; font-weight: bold }
/* GenericInserted */ .chroma .gi { color: #ecbe7b }
/* GenericOutput */ .chroma .go { color: #43454f }
/* GenericPrompt */ .chroma .gp { color: #c9c9c9 }
/* GenericStrong */ .chroma .gs { color: #cf5967; font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #cf5967; font-style: italic }
/* GenericTraceback */ .chroma .gt { color: #c9c9c9 }
/* GenericUnderline */ .chroma .gl { color: #c9c9c9; text-decoration: underline }
/* TextWhitespace */ .chroma .w { color: #c9c9c9 }
body { color: #282c34; }
</style><body class="bg">
<pre tabindex="0" class="chroma"><code><span class="line"><span class="cl">0 &gt;= nw - p
</span></span><span class="line"><span class="cl">1 &gt;= 2(1) - (1)
</span></span><span class="line"><span class="cl">1 &gt;= 2 - 1
</span></span><span class="line"><span class="cl">1 &gt;= 1
</span></span></code></pre>
</body>
</html>
</div></li>
</ul>

<p><strong>XOR</strong></p>

<p><strong>Step. 1)</strong> Construct a truth table for AND</p>

<table>
<thead>
<tr>
<th>X1</th>
<th>X2</th>
<th>Y</th>
</tr>
</thead>

<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>

<tr>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>

<tr>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>

<tr>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>Assume the weights are initialized to W1 = W2 = 1</p>

<p>Calculate the net input:</p>

<table>
<thead>
<tr>
<th>$X_1X_2 =$</th>
<th>$X_1W_1 +$</th>
<th>$X_2W_2$</th>
<th>= $Ans$</th>
</tr>
</thead>

<tbody>
<tr>
<td>(0, 0)</td>
<td>0 x 1</td>
<td>0 x 1</td>
<td>0</td>
</tr>

<tr>
<td>(0, 1)</td>
<td>0 x 1</td>
<td>1 x 1</td>
<td>1</td>
</tr>

<tr>
<td>(1, 0)</td>
<td>1 x 1</td>
<td>0 x 1</td>
<td>1</td>
</tr>

<tr>
<td>(1, 1)</td>
<td>1 x 1</td>
<td>1 x 1</td>
<td>2</td>
</tr>
</tbody>
</table>

<p>Assume the weights are initialized to W2 = 1,  W2 = -1</p>

<p>Calculate the net input:</p>

<table>
<thead>
<tr>
<th>$X_1X_2 =$</th>
<th>$X_1W_1 +$</th>
<th>$X_2W_2$</th>
<th>= $Ans$</th>
</tr>
</thead>

<tbody>
<tr>
<td>(0, 0)</td>
<td>0 x 1</td>
<td>0 x -1</td>
<td>0</td>
</tr>

<tr>
<td>(0, 1)</td>
<td>0 x 1</td>
<td>1 x -1</td>
<td>-1</td>
</tr>

<tr>
<td>(1, 0)</td>
<td>1 x 1</td>
<td>0 x -1</td>
<td>1</td>
</tr>

<tr>
<td>(1, 1)</td>
<td>1 x 1</td>
<td>1 x -1</td>
<td>0</td>
</tr>
</tbody>
</table>

<p><strong>Step 2)</strong> $\therefore Z = X_1\bar{X_2} + \bar{X}X_2$</p>

<table>
<thead>
<tr>
<th>X1</th>
<th>X2</th>
<th>Z1</th>
</tr>
</thead>

<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>

<tr>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>

<tr>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>

<tr>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>

<table>
<thead>
<tr>
<th>X1</th>
<th>X2</th>
<th>Z2</th>
</tr>
</thead>

<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>

<tr>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>

<tr>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>

<tr>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>

<p><strong>Step 3)</strong> $Z_1 = X_1 \bar{X_2}$,Weight = (1, -1)</p>

<table>
<thead>
<tr>
<th>$X_1X_2 =$</th>
<th>$X_1W_1 +$</th>
<th>$X_2W_2$</th>
<th>= $Ans$</th>
</tr>
</thead>

<tbody>
<tr>
<td>(0, 0)</td>
<td>0 x 1</td>
<td>0 x -1</td>
<td>0</td>
</tr>

<tr>
<td>(0, 1)</td>
<td>0 x 1</td>
<td>1 x -1</td>
<td>-1</td>
</tr>

<tr>
<td>(1, 0)</td>
<td>1 x 1</td>
<td>0 x -1</td>
<td>1</td>
</tr>

<tr>
<td>(1, 1)</td>
<td>1 x 1</td>
<td>1 x -1</td>
<td>0</td>
</tr>
</tbody>
</table>

<div class="code-block"><html>
<style type="text/css">
/* Background */ .bg { color: #282c34 }
/* PreWrapper */ .chroma { color: #c9c9c9color: #282c34; }
/* Other */ .chroma .x { color: #c9c9c9 }
/* Error */ .chroma .err { color: #cf5967 }
/* CodeLine */ .chroma .cl { color: #c9c9c9 }
/* LineTableTD */ .chroma .lntd { vertical-align: top; padding: 0; margin: 0; border: 0;color: #c9c9c9 }
/* LineTable */ .chroma .lntable { border-spacing: 0; padding: 0; margin: 0; border: 0;color: #c9c9c9 }
/* LineHighlight */ .chroma .hl { color: #c9c9c9; background-color: #e5e5e5 }
/* LineNumbersTable */ .chroma .lnt { white-space: pre; user-select: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #939599 }
/* LineNumbers */ .chroma .ln { white-space: pre; user-select: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #939599 }
/* Line */ .chroma .line { display: flex;color: #c9c9c9 }
/* Keyword */ .chroma .k { color: #7fbaf5 }
/* KeywordConstant */ .chroma .kc { color: #cf5967; background-color: #43454f }
/* KeywordDeclaration */ .chroma .kd { color: #7fbaf5 }
/* KeywordNamespace */ .chroma .kn { color: #bc74c4 }
/* KeywordPseudo */ .chroma .kp { color: #bc74c4 }
/* KeywordReserved */ .chroma .kr { color: #7fbaf5 }
/* KeywordType */ .chroma .kt { color: #57c7ff; font-weight: bold }
/* Name */ .chroma .n { color: #c9c9c9 }
/* NameAttribute */ .chroma .na { color: #bc74c4 }
/* NameBuiltin */ .chroma .nb { color: #7fbaf5 }
/* NameBuiltinPseudo */ .chroma .bp { color: #7fbaf5 }
/* NameClass */ .chroma .nc { color: #ecbe7b }
/* NameConstant */ .chroma .no { color: #ecbe7b }
/* NameDecorator */ .chroma .nd { color: #ecbe7b }
/* NameEntity */ .chroma .ni { color: #c9c9c9 }
/* NameException */ .chroma .ne { color: #cf5967 }
/* NameFunction */ .chroma .nf { color: #57c7ff }
/* NameFunctionMagic */ .chroma .fm { color: #c9c9c9 }
/* NameLabel */ .chroma .nl { color: #cf5967 }
/* NameNamespace */ .chroma .nn { color: #c9c9c9 }
/* NameOther */ .chroma .nx { color: #c9c9c9 }
/* NameProperty */ .chroma .py { color: #c9c9c9 }
/* NameTag */ .chroma .nt { color: #bc74c4 }
/* NameVariable */ .chroma .nv { color: #bc74c4; font-style: italic }
/* NameVariableClass */ .chroma .vc { color: #57c7ff; font-weight: bold }
/* NameVariableGlobal */ .chroma .vg { color: #ecbe7b }
/* NameVariableInstance */ .chroma .vi { color: #57c7ff }
/* NameVariableMagic */ .chroma .vm { color: #c9c9c9 }
/* Literal */ .chroma .l { color: #c9c9c9 }
/* LiteralDate */ .chroma .ld { color: #57c7ff }
/* LiteralString */ .chroma .s { color: #82cc6a }
/* LiteralStringAffix */ .chroma .sa { color: #82cc6a }
/* LiteralStringBacktick */ .chroma .sb { color: #57c7ff }
/* LiteralStringChar */ .chroma .sc { color: #57c7ff }
/* LiteralStringDelimiter */ .chroma .dl { color: #82cc6a }
/* LiteralStringDoc */ .chroma .sd { color: #82cc6a }
/* LiteralStringDouble */ .chroma .s2 { color: #82cc6a }
/* LiteralStringEscape */ .chroma .se { color: #56b6c2 }
/* LiteralStringHeredoc */ .chroma .sh { color: #56b6c2 }
/* LiteralStringInterpol */ .chroma .si { color: #82cc6a }
/* LiteralStringOther */ .chroma .sx { color: #82cc6a }
/* LiteralStringRegex */ .chroma .sr { color: #57c7ff }
/* LiteralStringSingle */ .chroma .s1 { color: #82cc6a }
/* LiteralStringSymbol */ .chroma .ss { color: #82cc6a }
/* LiteralNumber */ .chroma .m { color: #56b6c2 }
/* LiteralNumberBin */ .chroma .mb { color: #57c7ff }
/* LiteralNumberFloat */ .chroma .mf { color: #56b6c2 }
/* LiteralNumberHex */ .chroma .mh { color: #57c7ff }
/* LiteralNumberInteger */ .chroma .mi { color: #56b6c2 }
/* LiteralNumberIntegerLong */ .chroma .il { color: #56b6c2 }
/* LiteralNumberOct */ .chroma .mo { color: #57c7ff }
/* Operator */ .chroma .o { color: #bc74c4 }
/* OperatorWord */ .chroma .ow { color: #bc74c4 }
/* Punctuation */ .chroma .p { color: #56b6c2 }
/* Comment */ .chroma .c { color: #3e4460 }
/* CommentHashbang */ .chroma .ch { color: #3e4460; font-style: italic }
/* CommentMultiline */ .chroma .cm { color: #3e4460 }
/* CommentSingle */ .chroma .c1 { color: #3e4460 }
/* CommentSpecial */ .chroma .cs { color: #bc74c4; font-style: italic }
/* CommentPreproc */ .chroma .cp { color: #7fbaf5 }
/* CommentPreprocFile */ .chroma .cpf { color: #7fbaf5 }
/* Generic */ .chroma .g { color: #c9c9c9 }
/* GenericDeleted */ .chroma .gd { color: #cf5967 }
/* GenericEmph */ .chroma .ge { color: #c9c9c9; text-decoration: underline }
/* GenericError */ .chroma .gr { color: #cf5967; font-weight: bold }
/* GenericHeading */ .chroma .gh { color: #ecbe7b; font-weight: bold }
/* GenericInserted */ .chroma .gi { color: #ecbe7b }
/* GenericOutput */ .chroma .go { color: #43454f }
/* GenericPrompt */ .chroma .gp { color: #c9c9c9 }
/* GenericStrong */ .chroma .gs { color: #cf5967; font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #cf5967; font-style: italic }
/* GenericTraceback */ .chroma .gt { color: #c9c9c9 }
/* GenericUnderline */ .chroma .gl { color: #c9c9c9; text-decoration: underline }
/* TextWhitespace */ .chroma .w { color: #c9c9c9 }
body { color: #282c34; }
</style><body class="bg">
<pre tabindex="0" class="chroma"><code><span class="line"><span class="cl">0 &gt;= nw - p
</span></span><span class="line"><span class="cl">1 &gt;= 2(1) - 1
</span></span><span class="line"><span class="cl">1 &gt;= 1
</span></span></code></pre>
</body>
</html>
</div>
<p><strong>Step 4)</strong> $Z_2 = \bar{X_1}X_2$, Weight = (-1, 1)</p>

<table>
<thead>
<tr>
<th>$X_1X_2 =$</th>
<th>$X_1W_1 +$</th>
<th>$X_2W_2$</th>
<th>= $Ans$</th>
</tr>
</thead>

<tbody>
<tr>
<td>(0, 0)</td>
<td>0 x -1</td>
<td>0 x 1</td>
<td>0</td>
</tr>

<tr>
<td>(0, 1)</td>
<td>0 x -1</td>
<td>1 x 1</td>
<td>1</td>
</tr>

<tr>
<td>(1, 0)</td>
<td>1 x -1</td>
<td>0 x 1</td>
<td>-1</td>
</tr>

<tr>
<td>(1, 1)</td>
<td>1 x -1</td>
<td>1 x 1</td>
<td>0</td>
</tr>
</tbody>
</table>

<div class="code-block"><html>
<style type="text/css">
/* Background */ .bg { color: #282c34 }
/* PreWrapper */ .chroma { color: #c9c9c9color: #282c34; }
/* Other */ .chroma .x { color: #c9c9c9 }
/* Error */ .chroma .err { color: #cf5967 }
/* CodeLine */ .chroma .cl { color: #c9c9c9 }
/* LineTableTD */ .chroma .lntd { vertical-align: top; padding: 0; margin: 0; border: 0;color: #c9c9c9 }
/* LineTable */ .chroma .lntable { border-spacing: 0; padding: 0; margin: 0; border: 0;color: #c9c9c9 }
/* LineHighlight */ .chroma .hl { color: #c9c9c9; background-color: #e5e5e5 }
/* LineNumbersTable */ .chroma .lnt { white-space: pre; user-select: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #939599 }
/* LineNumbers */ .chroma .ln { white-space: pre; user-select: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #939599 }
/* Line */ .chroma .line { display: flex;color: #c9c9c9 }
/* Keyword */ .chroma .k { color: #7fbaf5 }
/* KeywordConstant */ .chroma .kc { color: #cf5967; background-color: #43454f }
/* KeywordDeclaration */ .chroma .kd { color: #7fbaf5 }
/* KeywordNamespace */ .chroma .kn { color: #bc74c4 }
/* KeywordPseudo */ .chroma .kp { color: #bc74c4 }
/* KeywordReserved */ .chroma .kr { color: #7fbaf5 }
/* KeywordType */ .chroma .kt { color: #57c7ff; font-weight: bold }
/* Name */ .chroma .n { color: #c9c9c9 }
/* NameAttribute */ .chroma .na { color: #bc74c4 }
/* NameBuiltin */ .chroma .nb { color: #7fbaf5 }
/* NameBuiltinPseudo */ .chroma .bp { color: #7fbaf5 }
/* NameClass */ .chroma .nc { color: #ecbe7b }
/* NameConstant */ .chroma .no { color: #ecbe7b }
/* NameDecorator */ .chroma .nd { color: #ecbe7b }
/* NameEntity */ .chroma .ni { color: #c9c9c9 }
/* NameException */ .chroma .ne { color: #cf5967 }
/* NameFunction */ .chroma .nf { color: #57c7ff }
/* NameFunctionMagic */ .chroma .fm { color: #c9c9c9 }
/* NameLabel */ .chroma .nl { color: #cf5967 }
/* NameNamespace */ .chroma .nn { color: #c9c9c9 }
/* NameOther */ .chroma .nx { color: #c9c9c9 }
/* NameProperty */ .chroma .py { color: #c9c9c9 }
/* NameTag */ .chroma .nt { color: #bc74c4 }
/* NameVariable */ .chroma .nv { color: #bc74c4; font-style: italic }
/* NameVariableClass */ .chroma .vc { color: #57c7ff; font-weight: bold }
/* NameVariableGlobal */ .chroma .vg { color: #ecbe7b }
/* NameVariableInstance */ .chroma .vi { color: #57c7ff }
/* NameVariableMagic */ .chroma .vm { color: #c9c9c9 }
/* Literal */ .chroma .l { color: #c9c9c9 }
/* LiteralDate */ .chroma .ld { color: #57c7ff }
/* LiteralString */ .chroma .s { color: #82cc6a }
/* LiteralStringAffix */ .chroma .sa { color: #82cc6a }
/* LiteralStringBacktick */ .chroma .sb { color: #57c7ff }
/* LiteralStringChar */ .chroma .sc { color: #57c7ff }
/* LiteralStringDelimiter */ .chroma .dl { color: #82cc6a }
/* LiteralStringDoc */ .chroma .sd { color: #82cc6a }
/* LiteralStringDouble */ .chroma .s2 { color: #82cc6a }
/* LiteralStringEscape */ .chroma .se { color: #56b6c2 }
/* LiteralStringHeredoc */ .chroma .sh { color: #56b6c2 }
/* LiteralStringInterpol */ .chroma .si { color: #82cc6a }
/* LiteralStringOther */ .chroma .sx { color: #82cc6a }
/* LiteralStringRegex */ .chroma .sr { color: #57c7ff }
/* LiteralStringSingle */ .chroma .s1 { color: #82cc6a }
/* LiteralStringSymbol */ .chroma .ss { color: #82cc6a }
/* LiteralNumber */ .chroma .m { color: #56b6c2 }
/* LiteralNumberBin */ .chroma .mb { color: #57c7ff }
/* LiteralNumberFloat */ .chroma .mf { color: #56b6c2 }
/* LiteralNumberHex */ .chroma .mh { color: #57c7ff }
/* LiteralNumberInteger */ .chroma .mi { color: #56b6c2 }
/* LiteralNumberIntegerLong */ .chroma .il { color: #56b6c2 }
/* LiteralNumberOct */ .chroma .mo { color: #57c7ff }
/* Operator */ .chroma .o { color: #bc74c4 }
/* OperatorWord */ .chroma .ow { color: #bc74c4 }
/* Punctuation */ .chroma .p { color: #56b6c2 }
/* Comment */ .chroma .c { color: #3e4460 }
/* CommentHashbang */ .chroma .ch { color: #3e4460; font-style: italic }
/* CommentMultiline */ .chroma .cm { color: #3e4460 }
/* CommentSingle */ .chroma .c1 { color: #3e4460 }
/* CommentSpecial */ .chroma .cs { color: #bc74c4; font-style: italic }
/* CommentPreproc */ .chroma .cp { color: #7fbaf5 }
/* CommentPreprocFile */ .chroma .cpf { color: #7fbaf5 }
/* Generic */ .chroma .g { color: #c9c9c9 }
/* GenericDeleted */ .chroma .gd { color: #cf5967 }
/* GenericEmph */ .chroma .ge { color: #c9c9c9; text-decoration: underline }
/* GenericError */ .chroma .gr { color: #cf5967; font-weight: bold }
/* GenericHeading */ .chroma .gh { color: #ecbe7b; font-weight: bold }
/* GenericInserted */ .chroma .gi { color: #ecbe7b }
/* GenericOutput */ .chroma .go { color: #43454f }
/* GenericPrompt */ .chroma .gp { color: #c9c9c9 }
/* GenericStrong */ .chroma .gs { color: #cf5967; font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #cf5967; font-style: italic }
/* GenericTraceback */ .chroma .gt { color: #c9c9c9 }
/* GenericUnderline */ .chroma .gl { color: #c9c9c9; text-decoration: underline }
/* TextWhitespace */ .chroma .w { color: #c9c9c9 }
body { color: #282c34; }
</style><body class="bg">
<pre tabindex="0" class="chroma"><code><span class="line"><span class="cl">0 &gt;= nw - p
</span></span><span class="line"><span class="cl">1 &gt;= 2(1) - 1
</span></span><span class="line"><span class="cl">1 &gt;= 1
</span></span></code></pre>
</body>
</html>
</div>
<p><strong>Step 5)</strong> $Y = Z_1$ or $Z_2$</p>

<table>
<thead>
<tr>
<th>X1</th>
<th>X2</th>
<th>Y</th>
<th>Z1</th>
<th>Z2</th>
</tr>
</thead>

<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>

<tr>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>

<tr>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>

<tr>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>Assume the weights are initialized to $V_1 = V_2 = 1$</p>

<p>$V_1 = V_2 = 1$</p>

<table>
<thead>
<tr>
<th>$Z_1Z_2 =$</th>
<th>$Z_1V_1 +$</th>
<th>$Z_2V_2$</th>
<th>= $Ans$</th>
</tr>
</thead>

<tbody>
<tr>
<td>(0, 0)</td>
<td>0 x 1</td>
<td>0 x 1</td>
<td>0</td>
</tr>

<tr>
<td>(0, 1)</td>
<td>0 x 1</td>
<td>1 x 1</td>
<td>1</td>
</tr>

<tr>
<td>(1, 0)</td>
<td>1 x 1</td>
<td>0 x 1</td>
<td>1</td>
</tr>

<tr>
<td>(1, 1)</td>
<td>1 x 1</td>
<td>0 x 1</td>
<td>0</td>
</tr>
</tbody>
</table>

<div class="code-block"><html>
<style type="text/css">
/* Background */ .bg { color: #282c34 }
/* PreWrapper */ .chroma { color: #c9c9c9color: #282c34; }
/* Other */ .chroma .x { color: #c9c9c9 }
/* Error */ .chroma .err { color: #cf5967 }
/* CodeLine */ .chroma .cl { color: #c9c9c9 }
/* LineTableTD */ .chroma .lntd { vertical-align: top; padding: 0; margin: 0; border: 0;color: #c9c9c9 }
/* LineTable */ .chroma .lntable { border-spacing: 0; padding: 0; margin: 0; border: 0;color: #c9c9c9 }
/* LineHighlight */ .chroma .hl { color: #c9c9c9; background-color: #e5e5e5 }
/* LineNumbersTable */ .chroma .lnt { white-space: pre; user-select: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #939599 }
/* LineNumbers */ .chroma .ln { white-space: pre; user-select: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em;color: #939599 }
/* Line */ .chroma .line { display: flex;color: #c9c9c9 }
/* Keyword */ .chroma .k { color: #7fbaf5 }
/* KeywordConstant */ .chroma .kc { color: #cf5967; background-color: #43454f }
/* KeywordDeclaration */ .chroma .kd { color: #7fbaf5 }
/* KeywordNamespace */ .chroma .kn { color: #bc74c4 }
/* KeywordPseudo */ .chroma .kp { color: #bc74c4 }
/* KeywordReserved */ .chroma .kr { color: #7fbaf5 }
/* KeywordType */ .chroma .kt { color: #57c7ff; font-weight: bold }
/* Name */ .chroma .n { color: #c9c9c9 }
/* NameAttribute */ .chroma .na { color: #bc74c4 }
/* NameBuiltin */ .chroma .nb { color: #7fbaf5 }
/* NameBuiltinPseudo */ .chroma .bp { color: #7fbaf5 }
/* NameClass */ .chroma .nc { color: #ecbe7b }
/* NameConstant */ .chroma .no { color: #ecbe7b }
/* NameDecorator */ .chroma .nd { color: #ecbe7b }
/* NameEntity */ .chroma .ni { color: #c9c9c9 }
/* NameException */ .chroma .ne { color: #cf5967 }
/* NameFunction */ .chroma .nf { color: #57c7ff }
/* NameFunctionMagic */ .chroma .fm { color: #c9c9c9 }
/* NameLabel */ .chroma .nl { color: #cf5967 }
/* NameNamespace */ .chroma .nn { color: #c9c9c9 }
/* NameOther */ .chroma .nx { color: #c9c9c9 }
/* NameProperty */ .chroma .py { color: #c9c9c9 }
/* NameTag */ .chroma .nt { color: #bc74c4 }
/* NameVariable */ .chroma .nv { color: #bc74c4; font-style: italic }
/* NameVariableClass */ .chroma .vc { color: #57c7ff; font-weight: bold }
/* NameVariableGlobal */ .chroma .vg { color: #ecbe7b }
/* NameVariableInstance */ .chroma .vi { color: #57c7ff }
/* NameVariableMagic */ .chroma .vm { color: #c9c9c9 }
/* Literal */ .chroma .l { color: #c9c9c9 }
/* LiteralDate */ .chroma .ld { color: #57c7ff }
/* LiteralString */ .chroma .s { color: #82cc6a }
/* LiteralStringAffix */ .chroma .sa { color: #82cc6a }
/* LiteralStringBacktick */ .chroma .sb { color: #57c7ff }
/* LiteralStringChar */ .chroma .sc { color: #57c7ff }
/* LiteralStringDelimiter */ .chroma .dl { color: #82cc6a }
/* LiteralStringDoc */ .chroma .sd { color: #82cc6a }
/* LiteralStringDouble */ .chroma .s2 { color: #82cc6a }
/* LiteralStringEscape */ .chroma .se { color: #56b6c2 }
/* LiteralStringHeredoc */ .chroma .sh { color: #56b6c2 }
/* LiteralStringInterpol */ .chroma .si { color: #82cc6a }
/* LiteralStringOther */ .chroma .sx { color: #82cc6a }
/* LiteralStringRegex */ .chroma .sr { color: #57c7ff }
/* LiteralStringSingle */ .chroma .s1 { color: #82cc6a }
/* LiteralStringSymbol */ .chroma .ss { color: #82cc6a }
/* LiteralNumber */ .chroma .m { color: #56b6c2 }
/* LiteralNumberBin */ .chroma .mb { color: #57c7ff }
/* LiteralNumberFloat */ .chroma .mf { color: #56b6c2 }
/* LiteralNumberHex */ .chroma .mh { color: #57c7ff }
/* LiteralNumberInteger */ .chroma .mi { color: #56b6c2 }
/* LiteralNumberIntegerLong */ .chroma .il { color: #56b6c2 }
/* LiteralNumberOct */ .chroma .mo { color: #57c7ff }
/* Operator */ .chroma .o { color: #bc74c4 }
/* OperatorWord */ .chroma .ow { color: #bc74c4 }
/* Punctuation */ .chroma .p { color: #56b6c2 }
/* Comment */ .chroma .c { color: #3e4460 }
/* CommentHashbang */ .chroma .ch { color: #3e4460; font-style: italic }
/* CommentMultiline */ .chroma .cm { color: #3e4460 }
/* CommentSingle */ .chroma .c1 { color: #3e4460 }
/* CommentSpecial */ .chroma .cs { color: #bc74c4; font-style: italic }
/* CommentPreproc */ .chroma .cp { color: #7fbaf5 }
/* CommentPreprocFile */ .chroma .cpf { color: #7fbaf5 }
/* Generic */ .chroma .g { color: #c9c9c9 }
/* GenericDeleted */ .chroma .gd { color: #cf5967 }
/* GenericEmph */ .chroma .ge { color: #c9c9c9; text-decoration: underline }
/* GenericError */ .chroma .gr { color: #cf5967; font-weight: bold }
/* GenericHeading */ .chroma .gh { color: #ecbe7b; font-weight: bold }
/* GenericInserted */ .chroma .gi { color: #ecbe7b }
/* GenericOutput */ .chroma .go { color: #43454f }
/* GenericPrompt */ .chroma .gp { color: #c9c9c9 }
/* GenericStrong */ .chroma .gs { color: #cf5967; font-weight: bold }
/* GenericSubheading */ .chroma .gu { color: #cf5967; font-style: italic }
/* GenericTraceback */ .chroma .gt { color: #c9c9c9 }
/* GenericUnderline */ .chroma .gl { color: #c9c9c9; text-decoration: underline }
/* TextWhitespace */ .chroma .w { color: #c9c9c9 }
body { color: #282c34; }
</style><body class="bg">
<pre tabindex="0" class="chroma"><code><span class="line"><span class="cl">0 &gt;= nw - p
</span></span><span class="line"><span class="cl">1 &gt;= (2)(1) - 0
</span></span><span class="line"><span class="cl">1 &gt;= 2
</span></span></code></pre>
</body>
</html>
</div><h2><a name="using-mamdani-fuzzy-model-design-a-fuzzy-logic-controller-to-determine-the-wash-time-of-domestic-washing-machine-assume-the-inputs-are-dirt-and-grease-on-clothes-use-three-descriptors-for-each-input-variable-and-five-descriptor-for-output-variables-derive-necessary-membership-functions-and-required-fuzzy-rules-for-the-application-2024-2023-may" class="heading-anchor" href="#using-mamdani-fuzzy-model-design-a-fuzzy-logic-controller-to-determine-the-wash-time-of-domestic-washing-machine-assume-the-inputs-are-dirt-and-grease-on-clothes-use-three-descriptors-for-each-input-variable-and-five-descriptor-for-output-variables-derive-necessary-membership-functions-and-required-fuzzy-rules-for-the-application-2024-2023-may" rel="nofollow" aria-hidden="true"></a>Using Mamdani fuzzy model design a fuzzy logic controller to determine the wash time of domestic washing machine. Assume the inputs are dirt and grease on clothes. Use three descriptors for each input variable and five descriptor for output variables. Derive necessary membership functions and required fuzzy rules for the application. (2024) (2023 May)</h2>
<iframe src="https://www.youtube.com/embed/THAk1O3HBDc" title="Mamdani Fuzzy model Sum with solved Example  | SOFT COMPUTING" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
<h2><a name="find-the-algebraic-sum-algebraic-product-bounded-sum-and-bounded-difference-of-the-given-fuzzy-sets-2022" class="heading-anchor" href="#find-the-algebraic-sum-algebraic-product-bounded-sum-and-bounded-difference-of-the-given-fuzzy-sets-2022" rel="nofollow" aria-hidden="true"></a>Find the algebraic sum, algebraic product, bounded sum, and bounded difference of the given fuzzy sets. (2022)</h2>
<p>$$\tilde{A} = \Bigg\lbrace \frac{0.2}{1} + \frac{0.3}{2} + \frac{0.4}{3} + \frac{0.5}{4} \Bigg\rbrace$$
$$\tilde{B} = \Bigg\lbrace \frac{0.1}{1} + \frac{0.2}{2} + \frac{0.2}{3} + \frac{0.1}{4} \Bigg\rbrace$$</p>

<iframe src="https://www.youtube.com/embed/6pFdocuBU7c" title="10. Find the algebraic sum &amp; product, bounded  sum &amp; difference given fuzzy Sets by Mahesh Huddar" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

<p><strong>Algebraic Sum</strong></p>

<p>$$=\tilde{A}+\tilde{B} - \tilde{A}\times\tilde{B}$$</p>

<p>$$ =
\Bigg\lbrace \frac{0.3}{1} + \frac{0.5}{2} + \frac{0.6}{3} + \frac{0.5}{4} \Bigg\rbrace -
\Bigg\lbrace \frac{0.02}{1} + \frac{0.06}{2} + \frac{0.08}{3} + \frac{0.5}{4} \Bigg\rbrace
$$</p>

<p><strong>Algebraic Product</strong></p>

<p>$$=\tilde{A}\times\tilde{B}$$</p>

<p>$$=\Bigg\lbrace \frac{0.02}{1} + \frac{0.06}{2} + \frac{0.08}{3} + \frac{0.5}{4} \Bigg\rbrace$$</p>

<p><strong>Bounded Sum</strong></p>

<p>$$=min\lbrace 1, {\tilde{A}+\tilde{B}}\rbrace$$</p>

<p>$$=min\Bigg\lbrace 1, \Bigg\lbrace \frac{0.3}{1} + \frac{0.5}{2} + \frac{0.6}{3} + \frac{1.5}{4} \Bigg\rbrace\Bigg\rbrace$$</p>

<p>$$=\Bigg\lbrace \frac{0.3}{1} + \frac{0.5}{2} + \frac{0.6}{3} + \frac{1}{4} \Bigg\rbrace$$</p>

<p><strong>Bounded Difference</strong></p>

<p>$$=min\lbrace 1, {\tilde{A}-\tilde{B}}\rbrace$$</p>

<p>$$=min\Bigg\lbrace 1, \Bigg\lbrace \frac{0.1}{1} + \frac{0.1}{2} + \frac{0.2}{3} + \frac{0.5}{4} \Bigg\rbrace\Bigg\rbrace$$</p>

<p>$$=\Bigg\lbrace \frac{0.1}{1} + \frac{0.1}{2} + \frac{0.2}{3} + \frac{0.5}{4} \Bigg\rbrace$$</p>
<h2><a name="from-a-standard-deck-of-playing-cards-a-single-card-is-drawn-the-probability-that-the-card-is-king-is-4-52-then-calculate-posterior-probability-p-king-face-which-means-the-drawn-face-card-is-a-king-card-2024-5-marks" class="heading-anchor" href="#from-a-standard-deck-of-playing-cards-a-single-card-is-drawn-the-probability-that-the-card-is-king-is-4-52-then-calculate-posterior-probability-p-king-face-which-means-the-drawn-face-card-is-a-king-card-2024-5-marks" rel="nofollow" aria-hidden="true"></a>From a standard deck of playing cards, a single card is drawn. The probability that the card is king is 4/52, then calculate posterior probability P(King|Face), which means the drawn face card is a king card. (2024 5 Marks)</h2>
<ul>
<li>Total number of card: $52$</li>
<li>Total number of King cards: $4$</li>
<li>Total number of Face cards: $12$ ($4$ kings, $4$ queens, and $4$ jacks)</li>
</ul>

<p>$P(King)$: probability that the card is King= $4 \over 52$ = $0.0769$</p>

<p>$P(Face)$: probability that a card is a face card = $12 \over 52$ = $0.2307$</p>

<p>$P(Face|King)$: probability of face card when we assume it is a king = $1$</p>

<p>$P(King|Face)$ = $P(Face|King)P(King) \over P(Face)$ = ${1 \times 0.0769 \over 0.2307}$ = $0.33$</p>

<p>$0.33$ is probability that a face card is king card.</p>
<h1><a name="10-marks" class="heading-anchor" href="#10-marks" rel="nofollow" aria-hidden="true"></a>10 Marks</h1><h2><a name="describe-the-architecture-of-a-typical-cnn-what-are-the-main-components-and-how-do-they-contribute-to-the-network-s-performance-in-image-recognition-tasks-2024-2023-dec-2022-2023-may-5-marks" class="heading-anchor" href="#describe-the-architecture-of-a-typical-cnn-what-are-the-main-components-and-how-do-they-contribute-to-the-network-s-performance-in-image-recognition-tasks-2024-2023-dec-2022-2023-may-5-marks" rel="nofollow" aria-hidden="true"></a>Describe the architecture of a typical CNN. What are the main components, and how do they contribute to the network's performance in image recognition tasks? (2024) (2023 Dec) (2022) (2023 May 5 Marks)</h2>
<p>CNN is deep learning algorithm which can take input as image assign importance to various object in the image and able to differentiate one from another.</p>

<p><img loading="lazy" src="../UT2/assets/Pasted%20image%2020241021023219.png" alt="" /></p>

<p>Components of CNN architecture:</p>

<ul>
<li><strong>Feature Extraction:</strong>

<ul>
<li><strong>Input Layer:</strong>

<ul>
<li>This layer passes data directly to fist hidden layer.</li>
<li>Here the data is multiplied by the first hidden layers weight.</li>
</ul></li>
<li><strong>Convolution Layer:</strong>

<ul>
<li>It takes an image and slides a small window, called a <strong>kernel</strong>, over it.</li>
<li>By stacking multiple convolution layers, the CNN can learn to recognize more complex patterns, helping it identify objects in pictures more accurately.</li>
</ul></li>
<li><strong>Pooling Layer:</strong>

<ul>
<li>Pooling layer summarize the features present in the reign of the feature map generated by convolution layer.</li>
<li><strong>Max Pooling</strong>

<ul>
<li>Max pooling works by sliding a small window (or kernel) over the feature map and selecting the <strong>maximum value</strong> within that window.</li>
</ul></li>
<li><strong>Average Pooling</strong>

<ul>
<li>This method helps to smooth out the feature map and can be better for capturing general patterns rather than just focusing on strong features.</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Classification</strong>

<ul>
<li><strong>Fully Connected Layer:</strong> This layer is responsible for integrating all the features learned from earlier convolution and pooling layers.</li>
<li><strong>Output:</strong> The output component of a CNN is often represented by a final layer that produces the prediction results.</li>
</ul></li>
</ul>
<h2><a name="what-is-cognitive-computing-and-how-does-it-differ-from-traditional-computing-list-the-process-of-building-a-cognitive-application-2024-2023-dec-2023-may-2023-may-5-marks" class="heading-anchor" href="#what-is-cognitive-computing-and-how-does-it-differ-from-traditional-computing-list-the-process-of-building-a-cognitive-application-2024-2023-dec-2023-may-2023-may-5-marks" rel="nofollow" aria-hidden="true"></a>What is cognitive computing, and how does it differ from traditional computing? List the process of building a cognitive application. (2024) (2023 Dec) (2023 May) (2023 May 5 Marks)</h2>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Cognitive Computing</th>
<th>Traditional Computing</th>
</tr>
</thead>

<tbody>
<tr>
<td>Learning and Adaptation</td>
<td>Learns and adapts</td>
<td>Relies on rules</td>
</tr>

<tr>
<td>Human-like Interaction</td>
<td>Understands and responds to natural language</td>
<td>Relies on structured input</td>
</tr>

<tr>
<td>Contextual Understanding</td>
<td>Understands context</td>
<td>Lacks context awareness</td>
</tr>

<tr>
<td>Reasoning and Problem-Solving</td>
<td>Reasons and solves problems</td>
<td>Follows algorithms</td>
</tr>

<tr>
<td>Self-Awareness</td>
<td>Monitors performance</td>
<td>Lacks self-awareness</td>
</tr>

<tr>
<td>Creativity</td>
<td>Generates new ideas</td>
<td>Lacks creativity</td>
</tr>

<tr>
<td>Empathy</td>
<td>Understands emotions</td>
<td>Lacks empathy</td>
</tr>

<tr>
<td>Common Sense</td>
<td>Applies common sense</td>
<td>Lacks common sense</td>
</tr>

<tr>
<td>Continuous Learning</td>
<td>Continuously learns</td>
<td>Lacks continuous learning</td>
</tr>

<tr>
<td>Explainability</td>
<td>Explains reasoning</td>
<td>Lacks explainability</td>
</tr>

<tr>
<td>Generalization</td>
<td>Generalizes knowledge</td>
<td>Lacks generalization</td>
</tr>
</tbody>
</table>

<p><strong>Here's a breakdown of the process of building a cognitive application:</strong></p>

<ol>
<li>Define the Problem

<ul>
<li><strong>Identify Objectives</strong>: Outline the application’s goals.</li>
<li><strong>Determine Scope</strong>: Specify use cases and boundaries.</li>
</ul></li>
<li>Gather Requirements

<ul>
<li><strong>Stakeholder Input</strong>: Collect requirements from stakeholders.</li>
<li><strong>User Needs</strong>: Understand end-user preferences.</li>
</ul></li>
<li>Data Collection and Preparation

<ul>
<li><strong>Data Sources</strong>: Identify and collect relevant data.</li>
<li><strong>Data Cleaning</strong>: Clean and preprocess data for quality.</li>
</ul></li>
<li>Model Development

<ul>
<li><strong>Choose Algorithms</strong>: Select appropriate machine learning methods.</li>
<li><strong>Model Training</strong>: Train and validate models on datasets.</li>
</ul></li>
<li>Deployment

<ul>
<li><strong>Launch Application</strong>: Deploy in a production environment.</li>
<li><strong>Monitor Performance</strong>: Track application metrics and health.</li>
</ul></li>
<li>Continuous Improvement

<ul>
<li><strong>Collect Feedback</strong>: Gather user input for enhancements.</li>
<li><strong>Model Refinement</strong>: Update models with new data.</li>
</ul></li>
</ol>
<h2><a name="explain-how-an-autoencoder-can-be-used-for-dimensionality-reduction-include-a-brief-description-of-how-the-encoder-and-decoder-parts-of-the-network-work-in-this-context-which-activation-function-is-best-for-an-autoencoder-2024-2023-may-2022" class="heading-anchor" href="#explain-how-an-autoencoder-can-be-used-for-dimensionality-reduction-include-a-brief-description-of-how-the-encoder-and-decoder-parts-of-the-network-work-in-this-context-which-activation-function-is-best-for-an-autoencoder-2024-2023-may-2022" rel="nofollow" aria-hidden="true"></a>Explain how an autoencoder can be used for dimensionality reduction. Include a brief description of how the encoder and decoder parts of the network work in this context. Which activation function is best for an autoencoder?  (2024) (2023 May) (2022)</h2>
<p><img loading="lazy" src="../UT2/assets/Pasted%20image%2020241020203851.png" alt="" /></p>

<p>An autoencoder is a type of neural network that can be used for dimensionality reduction. It consists of two main parts: an encoder and a decoder.</p>

<ul>
<li><strong>Encoder:</strong>

<ul>
<li>The encoder takes in the original input data, which is typically high-dimensional.</li>
<li>This compression is achieved by a series of layers with decreasing numbers of neurons, effectively reducing the dimensionality of the data.</li>
</ul></li>
<li><strong>Latent Space:</strong>

<ul>
<li>The dimensionality of the latent space determines the level of compression.</li>
<li>A smaller latent space can lead to more significant data compression, but it may also result in information loss.</li>
</ul></li>
<li><strong>Decoder:</strong>

<ul>
<li>The decoder takes the compressed representation from the encoder.</li>
<li>This is done by a series of layers with increasing numbers of neurons, ultimately aiming to recreate the original input dimensions.</li>
</ul></li>
</ul>

<p><strong>Dimensionality Reduction:</strong></p>

<p>Dimensionality reduction is a technique used to reduce the number of features (or dimensions) in a dataset while retaining as much of the important information as possible.</p>

<p>The key to dimensionality reduction lies in the latent space. During training, the autoencoder learns to map the original data to a lower-dimensional representation that captures the most important information.</p>

<p><strong>Best Activation Function for Autoencoders:</strong></p>

<ul>
<li><strong>ReLU (Rectified Linear Unit):</strong>

<ul>
<li>Widely used due to its simplicity and effectiveness.</li>
<li>It introduces non-linearity to the network, allowing it to learn complex patterns.</li>
</ul></li>
<li><strong>Leaky ReLU:</strong>

<ul>
<li>A variant of ReLU that introduces a small slope for negative inputs.</li>
<li>This helps prevent the &quot;dying ReLU&quot; problem, where neurons can become inactive.</li>
</ul></li>
<li><strong>Sigmoid:</strong>

<ul>
<li>Often used for output layers in classification tasks.</li>
<li>It produces outputs between 0 and 1, which can be interpreted as probabilities.</li>
</ul></li>
</ul>
<h2><a name="briefly-explain-data-science-for-multimodal-applications-2024-2023-may-2022" class="heading-anchor" href="#briefly-explain-data-science-for-multimodal-applications-2024-2023-may-2022" rel="nofollow" aria-hidden="true"></a>Briefly explain Data science for Multimodal applications. (2024) (2023 May) (2022)</h2>
<p>Data science for multimodal applications involves the integration and analysis of data from multiple sources or modalities, such as text, images, audio, and sensor data. This approach allows for richer insights and more comprehensive understanding of complex phenomena.</p>

<p>Here’s a brief overview:</p>

<p><strong>Key Components of Multimodal Data Science</strong></p>

<ol>
<li><strong>Data Collection</strong>:

<ul>
<li>Gather data from various modalities. For example, in a healthcare context, this might include medical imaging, patient records, and clinical notes.</li>
</ul></li>
<li><strong>Data Preprocessing</strong>:

<ul>
<li>Clean and preprocess each type of data to ensure compatibility. This may involve normalization, feature extraction, and conversion to a unified format.</li>
</ul></li>
<li><strong>Feature Fusion</strong>:

<ul>
<li>Combine features from different modalities. Techniques such as concatenation, attention mechanisms, or more advanced deep learning methods can be used to integrate the information.</li>
</ul></li>
<li><strong>Model Development</strong>:

<ul>
<li>Develop machine learning or deep learning models that can process multimodal inputs. Models may include architectures designed to handle multiple data types, such as CNNs for images and RNNs for text.</li>
</ul></li>
<li><strong>Training and Evaluation</strong>:

<ul>
<li>Train the model on combined datasets, ensuring that the performance is evaluated across all modalities to ensure robust predictions.</li>
</ul></li>
<li><strong>Deployment and Application</strong>:

<ul>
<li>Deploy the model in real-world scenarios, such as healthcare diagnostics, sentiment analysis combining text and audio, or autonomous systems using sensor data.</li>
</ul></li>
</ol>

<p><strong>Applications of Multimodal Data Science</strong></p>

<ul>
<li><strong>Healthcare</strong>: Integrating imaging data (e.g., MRIs) with patient histories and lab results for better diagnostic accuracy.</li>
<li><strong>Sentiment Analysis</strong>: Analyzing text, voice tone, and facial expressions to gauge customer satisfaction more effectively.</li>
<li><strong>Autonomous Vehicles</strong>: Combining data from cameras, LIDAR, and radar to enhance perception and decision-making.</li>
</ul>
<h2><a name="how-do-you-explain-random-forest-does-random-forest-need-pruning-explain-in-detail-2024-2023-may" class="heading-anchor" href="#how-do-you-explain-random-forest-does-random-forest-need-pruning-explain-in-detail-2024-2023-may" rel="nofollow" aria-hidden="true"></a>How do you explain random forest? Does random forest need pruning, explain in detail? (2024) (2023 May)</h2>
<p><img loading="lazy" src="../../Sem6/Sem/assets/Pasted%20image%2020240512221449.png" alt="" /></p>

<p>Random Forest is an ensemble learning technique primarily used for classification and regression tasks. It operates by constructing multiple decision trees during training and outputs the mode (classification) or mean (regression) of the individual trees’ predictions.</p>

<p>Here’s how it works:</p>

<ol>
<li><strong>Bootstrap Aggregation</strong>: It uses a method called bagging (Bootstrap Aggregating) to create multiple subsets of the training data.</li>
<li><strong>Random Feature Selection</strong>: For each split in a tree, a random subset of features is selected.</li>
<li><strong>Voting/Averaging</strong>: For classification, the final output is determined by a majority vote among the trees.</li>
</ol>

<p><strong>Why Pruning Isn't Necessary for Random Forests</strong></p>

<p>Pruning is a technique used to reduce the complexity of a decision tree by removing unnecessary branches. This helps to prevent overfitting, where the model becomes too tailored to the training data and performs poorly on new, unseen data.  </p>

<p>However, random forests are inherently less prone to overfitting due to two key factors:</p>

<ol>
<li><strong>Bagging:</strong>

<ul>
<li>By training each tree on a random subset of the data, the trees are less likely to learn the noise and idiosyncrasies of the specific training set.  </li>
<li>This diversity helps to reduce the variance of the model.</li>
</ul></li>
<li><strong>Feature Randomization:</strong>

<ul>
<li>Limiting the number of features considered at each node prevents the trees from becoming too deep and complex.</li>
<li>This further reduces the risk of overfitting.</li>
</ul></li>
</ol>
<h2><a name="describe-how-cognitive-computing-can-be-applied-in-healthcare-provide-specific-examples-of-tasks-or-problems-that-cognitive-computing-can-help-address-and-explain-the-potential-benefits-2024-2022" class="heading-anchor" href="#describe-how-cognitive-computing-can-be-applied-in-healthcare-provide-specific-examples-of-tasks-or-problems-that-cognitive-computing-can-help-address-and-explain-the-potential-benefits-2024-2022" rel="nofollow" aria-hidden="true"></a>Describe how cognitive computing can be applied in healthcare. Provide specific examples of tasks or problems that cognitive computing can help address, and explain the potential benefits. (2024) (2022)</h2>
<p>Cognitive computing combines artificial intelligence, machine learning, natural language processing, and data analytics to simulate human thought processes.</p>

<p>In healthcare, it can be applied in several ways to enhance decision-making, improve patient outcomes, and streamline operations.</p>

<p>Here are specific examples and their potential benefits:</p>

<ol>
<li><strong>Clinical Decision Support</strong>

<ul>
<li><strong>Example</strong>: Cognitive computing systems can analyze vast amounts of clinical data, including electronic health records (EHRs), lab results, and medical literature, to provide evidence-based recommendations to physicians.</li>
<li><strong>Benefits</strong>:

<ul>
<li><strong>Improved Diagnosis</strong>: By cross-referencing patient symptoms with extensive databases, cognitive systems can help identify diseases that might be overlooked.</li>
<li><strong>Personalized Treatment Plans</strong>: Tailoring recommendations based on the patient’s unique history and the latest research can lead to more effective treatments.</li>
</ul></li>
</ul></li>
<li><strong>Predictive Analytics</strong>

<ul>
<li><strong>Example</strong>: Cognitive computing can analyze patient data to predict outcomes such as the likelihood of readmission or the risk of developing certain conditions (e.g., diabetes, heart disease).</li>
<li><strong>Benefits</strong>:

<ul>
<li><strong>Proactive Care</strong>: Identifying at-risk patients allows for early interventions, reducing hospitalizations and improving overall health outcomes.</li>
<li><strong>Resource Optimization</strong>: Hospitals can better allocate resources and staffing based on predicted patient needs.</li>
</ul></li>
</ul></li>
<li><strong>Natural Language Processing (NLP)</strong>

<ul>
<li><strong>Example</strong>: NLP can be used to extract valuable insights from unstructured data in clinical notes, research articles, and patient feedback.</li>
<li><strong>Benefits</strong>:

<ul>
<li><strong>Enhanced Patient Interaction</strong>: Chatbots powered by NLP can assist patients in scheduling appointments, answering common questions, and providing health information, improving patient engagement.</li>
<li><strong>Streamlined Documentation</strong>: Automating the extraction and organization of information from clinical notes saves time for healthcare providers and reduces administrative burdens.</li>
</ul></li>
</ul></li>
<li><strong>Drug Discovery and Development</strong>

<ul>
<li><strong>Example</strong>: Cognitive computing can analyze chemical compounds, biological data, and clinical trial results to identify potential new drugs or predict the success of existing drugs in different populations.</li>
<li><strong>Benefits</strong>:

<ul>
<li><strong>Accelerated Research</strong>: By rapidly analyzing vast datasets, cognitive systems can significantly reduce the time and cost associated with drug development.</li>
<li><strong>Targeted Therapies</strong>: Understanding the genetic and molecular basis of diseases can lead to more effective targeted therapies, improving treatment efficacy.</li>
</ul></li>
</ul></li>
</ol>
<h2><a name="what-is-a-markov-decision-process-mdp-list-its-primary-components-explain-in-detail-2024-2023-may" class="heading-anchor" href="#what-is-a-markov-decision-process-mdp-list-its-primary-components-explain-in-detail-2024-2023-may" rel="nofollow" aria-hidden="true"></a>What is a Markov Decision Process (MDP)? List its primary components. Explain in detail. (2024)  (2023 May)</h2>
<iframe src="https://www.youtube.com/embed/zC8jkmlCDCU" title="Markov decision process in machine learning | Reinforcement learning | Lec-31 | Machine Learning" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>Markov decision process in machine learning | Reinforcement learning | Lec-31 | Machine Learning</iframe>

<p>A <strong>Markov Decision Process (MDP)</strong> is a mathematical framework used in machine learning to model sequential decision-making processes in stochastic environments.</p>

<p>Here are the key components and concepts associated with MDPs:</p>

<ol>
<li><strong>States (S):</strong>

<ul>
<li>Represents all possible situations the agent can be in.</li>
<li><strong>Example:</strong> A robot's position on a grid.</li>
</ul></li>
<li><strong>Actions (A):</strong>

<ul>
<li>Represents all possible actions the agent can take in each state.</li>
<li><strong>Example:</strong> Moving north, south, east, or west.</li>
</ul></li>
<li><strong>Transition Probability (P):</strong>

<ul>
<li>The probability of moving from one state to another given a specific action, relying only on the current state and action (Markov Property).</li>
</ul></li>
<li><strong>Reward Function (R):</strong>

<ul>
<li>The immediate reward received after transitioning between states due to an action.</li>
<li><strong>Example:</strong> Points earned after a game move.</li>
</ul></li>
</ol>

<p>Example:</p>

<p><img loading="lazy" src="assets/Pasted%20image%2020240828035224.jpg" alt="" /></p>

<p>An agent lives in the grid. The above example is a 3x4 grid. The grid has a START state(grid no 1,1). The purpose of the agent is to wander around the grid to finally reach the Blue Diamond (grid no 4,3). Under all circumstances, the agent should avoid the Fire grid (orange color, grid no 4,2). Also, the grid no 2,2 is a blocked grid, it acts as a wall hence the agent cannot enter it.</p>

<p>The agent can take any one of these actions: *<strong><em>UP, DOWN, LEFT, RIGHT</em></strong>*</p>

<p>*<strong><em>First Aim:</em></strong>* To find the shortest sequence getting from START to the Diamond. Two such sequences can be found:</p>

<ul>
<li>*<strong><em>RIGHT RIGHT UP UPRIGHT</em></strong>*</li>
<li>*<strong><em>UP UP RIGHT RIGHT RIGHT</em></strong>*</li>
</ul>
<h2><a name="how-does-class-imbalance-affect-classification-what-are-the-ways-to-solve-class-imbalanced-problems-2023-may-2022" class="heading-anchor" href="#how-does-class-imbalance-affect-classification-what-are-the-ways-to-solve-class-imbalanced-problems-2023-may-2022" rel="nofollow" aria-hidden="true"></a>How does class imbalance affect classification? What are the ways to solve class imbalanced problems?  (2023 May) (2022)</h2>
<p>Class imbalance occurs when the distribution of classes in a dataset is uneven. In other words, one class significantly outnumbers the other(s).</p>

<p>This imbalance can lead to biased models that prioritize the majority class, resulting in poor performance on the minority class.</p>

<p><strong>Affects of Class Imbalance:</strong></p>

<ul>
<li><strong>Biased Models:</strong> The model may learn to predict the majority class more accurately, neglecting the minority class.</li>
<li><strong>Low Sensitivity:</strong> The model may have difficulty detecting instances of the minority class.</li>
<li><strong>Overfitting:</strong> The model may overfit to the majority class, leading to poor generalization on unseen data.</li>
</ul>

<p><strong>Strategies to Address Class Imbalance:</strong></p>

<ol>
<li><strong>Data-Level Techniques:</strong>

<ul>
<li><strong>Oversampling:</strong>

<ul>
<li><strong>Random Oversampling:</strong> Duplicates instances from the minority class.</li>
</ul></li>
<li><strong>Undersampling:</strong>

<ul>
<li>Removes instances from the majority class.</li>
<li><strong>Random Undersampling:</strong> Randomly removes instances.</li>
</ul></li>
</ul></li>
<li><strong>Algorithm-Level Techniques:</strong>

<ul>
<li><strong>Cost-Sensitive Learning:</strong> Assigns different costs to errors made on different classes.</li>
<li><strong>Class Weighting:</strong> Assigns weights to different classes during training.</li>
<li><strong>Threshold Modification:</strong> Adjusts the classification threshold to improve sensitivity for the minority class.</li>
</ul></li>
<li><strong>Ensemble Methods:</strong>

<ul>
<li><strong>Bagging:</strong> Creates multiple models on different subsets of the data and combines their predictions.</li>
<li><strong>Boosting:</strong> Sequentially trains models, focusing on instances misclassified by previous models.</li>
</ul></li>
</ol>

<p><strong>Example:</strong></p>

<p><img loading="lazy" src="assets/1_GkhP_fliGHcijoiyp0I4Wg.webp" alt="" /></p>

<p>Consider a credit card fraud detection dataset where fraudulent transactions are significantly less frequent than legitimate ones. Here's how the above techniques can be applied:</p>

<ul>
<li><strong>Oversampling:</strong> Generate synthetic fraudulent transaction data using SMOTE.</li>
<li><strong>Class Weighting:</strong> Assign higher weights to fraudulent transactions during training.</li>
<li><strong>Cost-Sensitive Learning:</strong> Penalize the model more heavily for misclassifying fraudulent transactions.</li>
<li><strong>Ensemble Methods:</strong> Combine multiple models, such as decision trees and random forests, to improve overall performance.</li>
</ul>
<h2><a name="state-and-elaborate-the-applications-of-deep-learning-2023-dec-2024-5-marks" class="heading-anchor" href="#state-and-elaborate-the-applications-of-deep-learning-2023-dec-2024-5-marks" rel="nofollow" aria-hidden="true"></a>State and elaborate the applications of deep learning. (2023 Dec)  (2024 5 Marks)</h2>
<ul>
<li><strong>Computer Vision:</strong>

<ul>
<li><strong>Image Classification:</strong> Identifying and categorizing objects within images.  </li>
<li><strong>Object Detection:</strong> Locating and identifying objects within images.  </li>
<li><strong>Face Recognition:</strong> Recognizing individuals based on their facial features.  </li>
</ul></li>
<li><strong>Natural Language Processing (NLP):</strong>

<ul>
<li><strong>Machine Translation:</strong> Translating text from one language to another.</li>
<li><strong>Text Summarization:</strong> Condensing long texts into shorter summaries.  </li>
<li><strong>Text Generation:</strong> Generating human-quality text, such as articles, poems, or code.  </li>
<li><strong>Chatbots and Virtual Assistants:</strong> Developing conversational agents that can interact with users in natural language.</li>
</ul></li>
<li><strong>Speech Recognition:</strong>

<ul>
<li><strong>Voice Assistants:</strong> Enabling voice-controlled devices and applications.  </li>
<li><strong>Speech-to-Text Conversion:</strong> Converting spoken language into written text.</li>
</ul></li>
<li><strong>Healthcare:</strong>

<ul>
<li><strong>Drug Discovery:</strong> Identifying potential drug candidates.  </li>
<li><strong>Disease Diagnosis:</strong> Detecting diseases from medical images and patient records.  </li>
<li><strong>Personalized Medicine:</strong> Tailoring treatments to individual patients.</li>
</ul></li>
<li><strong>Recommendation Systems:</strong>

<ul>
<li><strong>Product Recommendations:</strong> Suggesting products to users based on their preferences.  </li>
<li><strong>Content Recommendations:</strong> Recommending movies, music, or articles.</li>
</ul></li>
</ul>
<h2><a name="list-three-industries-where-data-science-is-extensively-used-and-briefly-describe-one-application-in-each-industry-2024" class="heading-anchor" href="#list-three-industries-where-data-science-is-extensively-used-and-briefly-describe-one-application-in-each-industry-2024" rel="nofollow" aria-hidden="true"></a>List three industries where data science is extensively used and briefly describe one application in each industry. (2024)</h2>
<p>Data science is leveraged across various industries to extract insights from data, drive decision-making, and improve operational efficiencies.</p>

<ol>
<li><strong>Healthcare</strong>

<ul>
<li><strong>Application:</strong> Predictive Analytics for Patient Outcomes</li>
<li>Data science is used to analyze patient data, including electronic health records, genetic information, and demographic details, to predict health outcomes.</li>
</ul></li>
<li><strong>Finance</strong>

<ul>
<li><strong>Application: Fraud Detection</strong><br></li>
<li>Machine learning algorithms analyze transaction patterns and behaviors in real time, flagging anomalies that may indicate fraud.</li>
</ul></li>
<li><strong>Retail</strong>

<ul>
<li><strong>Application: Recommendation Systems</strong><br></li>
<li>Retailers use data science to develop recommendation systems that analyze customer purchase history, browsing behavior, and preferences to suggest products.</li>
<li>For example, e-commerce platforms like Amazon use sophisticated algorithms to recommend items based on user interactions and similar customer profiles.</li>
</ul></li>
</ol>
<h2><a name="state-ensemble-methods-and-describe-any-one-2023-dec" class="heading-anchor" href="#state-ensemble-methods-and-describe-any-one-2023-dec" rel="nofollow" aria-hidden="true"></a>State Ensemble methods and describe any one. (2023 Dec)</h2>
<iframe src="https://www.youtube.com/embed/qQjOWmf8I_I" title="Introduction to Ensemble Learning with Real Life Examples | Machine⚙️ Learning" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

<p>Ensemble learning is a powerful machine learning technique that improves predictive performance by combining multiple models, known as &quot;base learners&quot; or &quot;weak learners.&quot;</p>

<p>The core idea is that by aggregating the predictions of several models, the ensemble can achieve better results than any single model alone.</p>

<p><img loading="lazy" src="assets/1_3nhjhdNteP3GeMRSeCqtng.webp" alt="" /></p>

<p><strong>Types of Ensemble Classifiers</strong></p>

<p><img loading="lazy" src="../../Sem6/UT1/assets/Pasted%20image%2020240221054736.png" alt="" /></p>

<ul>
<li><strong>Bagging</strong>

<ul>
<li>Bootstrap Aggregating is the full form of Bagging.</li>
<li>Bagging generates multiple classifiers that are combined using average or majority voting.</li>
</ul></li>
<li><strong>Boosting</strong>

<ul>
<li>Boosting is done in a sequential manner which focus on weights on the dataset.</li>
</ul></li>
<li><strong>Ada Boosting</strong>

<ul>
<li>It is algorithm inside of Boosting.</li>
<li>It stands for <strong>Adoptive Boosting</strong></li>
<li>It combines multiple weak classifier into one strong classifier.</li>
<li><strong>Algorithm</strong>

<ul>
<li>Initialize one data</li>
<li>Assign equal weight to each item.</li>
<li>Provide this input to the model and identify from wrongly classified data points.</li>
<li>Increase the weight of wrongly classified data points &amp; again start processing the data until the results are satisfied.</li>
</ul></li>
</ul></li>
<li><strong>Random Forest</strong>

<ul>
<li><img loading="lazy" src="../../Sem6/Sem/assets/Pasted%20image%2020240512221449.png" alt="" /></li>
<li>Instead of relying on one decision tree, the random forest takes the prediction from each tree and based on the majority votes of predictions, and it predicts the final output.</li>
</ul></li>
</ul>
<h2><a name="illustrate-usage-of-taxonomies-and-ontologies-for-knowledge-representation-in-cognitive-systems-2023-dec" class="heading-anchor" href="#illustrate-usage-of-taxonomies-and-ontologies-for-knowledge-representation-in-cognitive-systems-2023-dec" rel="nofollow" aria-hidden="true"></a>Illustrate usage of taxonomies and ontologies for knowledge representation in cognitive systems. (2023 Dec)</h2>
<p><strong>Ontology</strong></p>

<ul>
<li><strong>Definition</strong>: A taxonomy is a hierarchical structure that categorizes concepts into parent-child relationships, where each child concept is a specific instance of its parent.</li>
<li><strong>Components:</strong>

<ul>
<li><strong>Classes (or Concepts):</strong> The basic entities or categories in the domain.</li>
<li><strong>Relationships:</strong> How classes or concepts are related (e.g., &quot;is a,&quot; &quot;part of&quot;).</li>
<li><strong>Attributes:</strong> Properties or characteristics of the concepts (e.g., &quot;has color&quot;).</li>
<li><strong>Instances:</strong> Specific examples of the classes (e.g., a specific car is an instance of the class &quot;Vehicle&quot;).</li>
</ul></li>
<li><strong>Example:</strong> In the medical domain, an ontology might include concepts like &quot;Disease,&quot; &quot;Symptom,&quot; &quot;Treatment,&quot; and their relationships (e.g., &quot;Disease has Symptom,&quot; &quot;Treatment addresses Disease&quot;).</li>
</ul>

<p><strong>Taxonomy</strong></p>

<ul>
<li><strong>Definition</strong>: An ontology is a more complex representation that defines a set of concepts within a domain and the relationships between those concepts, including properties and constraints.</li>
<li><strong>Components:</strong>

<ul>
<li><strong>Nodes:</strong> Represent categories or concepts.</li>
<li><strong>Edges:</strong> Represent the hierarchical relationships between nodes.</li>
</ul></li>
<li><strong>Example:</strong> A taxonomy in the animal kingdom might have &quot;Animal&quot; as the root, with branches like &quot;Mammal,&quot; &quot;Bird,&quot; &quot;Fish,&quot; etc., and further subcategories under each branch (e.g., &quot;Mammal&quot; could include &quot;Primates,&quot; &quot;Carnivores,&quot; etc.).</li>
</ul>

<p><strong>Integration in Cognitive Systems</strong></p>

<ol>
<li><strong>Knowledge Representation</strong>:

<ul>
<li>Taxonomies provide a straightforward structure for organizing knowledge, while ontologies add depth by defining relationships and properties.</li>
</ul></li>
<li><strong>Inference and Reasoning</strong>:

<ul>
<li>Cognitive systems can use ontologies to perform reasoning tasks, such as inferring new knowledge from existing information (e.g., if a symptom is associated with a specific disease, and a patient has that symptom, they might have the disease).</li>
</ul></li>
<li><strong>Natural Language Processing</strong>:

<ul>
<li>Taxonomies and ontologies can enhance NLP tasks by providing context and meaning to words.</li>
</ul></li>
<li><strong>Machine Learning</strong>:

<ul>
<li>By using taxonomies and ontologies, machine learning models can be trained with richer, semantically meaningful data, improving their performance in tasks like classification and prediction.</li>
</ul></li>
</ol>
<h2><a name="perform-a-case-study-on-a-book-recommendation-system-data-science-based-2023-dec" class="heading-anchor" href="#perform-a-case-study-on-a-book-recommendation-system-data-science-based-2023-dec" rel="nofollow" aria-hidden="true"></a>Perform a case study on a book recommendation system (data science based). (2023 Dec)</h2>
<p><strong>Problem Statement</strong></p>

<p>A popular online bookstore wants to enhance user experience and increase sales by providing personalized book recommendations. They aim to leverage customer data and purchase history to suggest relevant books that align with individual preferences.</p>

<p><strong>Solution Approach</strong></p>

<p>A collaborative filtering approach will be employed to recommend books. This method assumes that users who have similar tastes in the past will likely have similar tastes in the future.</p>

<p><strong>Data Collection and Preparation</strong></p>

<ul>
<li><strong>Customer Data:</strong> Gather information such as customer IDs, purchase history, ratings given to books, and demographics.</li>
<li><strong>Book Data:</strong> Collect metadata for each book, including title, author, genre, publication year, and keywords.</li>
<li><strong>Data Cleaning:</strong> Handle missing values, outliers, and inconsistencies in the data.</li>
<li><strong>Feature Engineering:</strong> Create additional features, such as book age or author popularity, to improve recommendation accuracy.</li>
</ul>

<p><strong>Model Building and Training</strong></p>

<ol>
<li><strong>User-Based Collaborative Filtering:</strong>

<ul>
<li>Calculate similarity between users based on their shared purchase history or ratings.</li>
<li>Recommend books to a user based on the preferences of similar users.</li>
</ul></li>
<li><strong>Item-Based Collaborative Filtering:</strong>

<ul>
<li>Calculate similarity between books based on their purchase patterns or ratings.</li>
<li>Recommend books to a user based on the similarity between the books they have purchased or rated and other books in the database.</li>
</ul></li>
<li><strong>Hybrid Approach:</strong>

<ul>
<li>Combine user-based and item-based collaborative filtering to leverage the strengths of both methods.</li>
</ul></li>
</ol>

<p><strong>Evaluation</strong></p>

<ul>
<li><strong>Evaluation Metrics:</strong> Use metrics like precision, recall, F1-score, and mean squared error to evaluate the accuracy of the recommendation system.</li>
<li><strong>A/B Testing:</strong> Conduct experiments to compare the performance of different recommendation algorithms and models.</li>
</ul>

<p><strong>Deployment and Refinement</strong></p>

<ul>
<li><strong>Integration:</strong> Integrate the recommendation system into the online bookstore's platform.</li>
<li><strong>Real-time Updates:</strong> Continuously update the recommendation system with new user data and book information.</li>
<li><strong>User Feedback:</strong> Gather user feedback to improve the system's accuracy and relevance.</li>
</ul>

<p><strong>Case Study Example: Amazon</strong></p>

<p>Amazon is a prime example of a successful book recommendation system. They use a combination of collaborative filtering, content-based filtering, and other techniques to suggest books to their customers. Amazon's recommendation system has been instrumental in driving sales and enhancing user satisfaction.</p>
<h2><a name="describe-the-properties-of-fuzzy-sets-with-an-example-2023-dec" class="heading-anchor" href="#describe-the-properties-of-fuzzy-sets-with-an-example-2023-dec" rel="nofollow" aria-hidden="true"></a>Describe the properties of Fuzzy Sets with an example. (2023 Dec)</h2>
<iframe src="https://www.youtube.com/embed/yAG_To4DhDs" title="Fuzzy Set Properties ll Soft Computing Course Explained in Hindi" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
<h2><a name="define-cognitive-computing-and-draw-a-diagram-of-the-elements-of-a-cognitive-system-explaining-each-element-2022" class="heading-anchor" href="#define-cognitive-computing-and-draw-a-diagram-of-the-elements-of-a-cognitive-system-explaining-each-element-2022" rel="nofollow" aria-hidden="true"></a>Define Cognitive Computing and draw a diagram of the elements of a cognitive system, explaining each element. (2022)</h2>
<p>Cognitive computing refers to technology that simulates human thought processes in a complex and dynamic environment.</p>

<p>It combines artificial intelligence (AI), machine learning, natural language processing, and data mining to enable machines to understand, reason, and learn from vast amounts of data.</p>

<pre class='mermaid'>flowchart TD
    A["Data Sources
    (Structured & Unstructured Data)"] --> B["Data Processing
    (Data Cleaning, Transformation)"]
    B --> C["Machine Learning
    (Algorithms for Learning Patterns and Insights)"]
    C --> D["Natural Language Processing
    (Understanding & Generating Text)"]
    D --> E["Reasoning & Learning
    (Inferencing from Data & Knowledge)"]
    E --> F["User Interface
    (Interaction with Users through GUI)"]
    F --> G["Feedback Loop
    (Learning from User Interactions)"]
</pre>
<ol>
<li><strong>Data Sources</strong>:

<ul>
<li><strong>Description</strong>: Includes structured (e.g., databases) and unstructured data (e.g., text, images).</li>
<li><strong>Function</strong>: Provides raw data for analysis.</li>
</ul></li>
<li><strong>Data Processing</strong>:

<ul>
<li><strong>Description</strong>: Involves cleaning and transforming data.</li>
<li><strong>Function</strong>: Ensures data is accurate and ready for analysis.</li>
</ul></li>
<li><strong>Machine Learning</strong>:

<ul>
<li><strong>Description</strong>: Uses algorithms to find patterns in data.</li>
<li><strong>Function</strong>: Enables learning from data to improve predictions.</li>
</ul></li>
<li><strong>Natural Language Processing (NLP)</strong>:

<ul>
<li><strong>Description</strong>: Facilitates interaction between computers and human language.</li>
<li><strong>Function</strong>: Allows understanding and generation of text.</li>
</ul></li>
<li><strong>Reasoning &amp; Learning</strong>:

<ul>
<li><strong>Description</strong>: Involves making inferences and decisions.</li>
<li><strong>Function</strong>: Adapts behavior based on learned knowledge.</li>
</ul></li>
<li><strong>User Interface</strong>:

<ul>
<li><strong>Description</strong>: The medium for user interaction with the system.</li>
<li><strong>Function</strong>: Enables users to query and receive responses.</li>
</ul></li>
<li><strong>Feedback Loop</strong>:

<ul>
<li><strong>Description</strong>: Captures interactions to enhance performance.</li>
<li><strong>Function</strong>: Allows the system to learn from user feedback.</li>
</ul></li>
</ol>
<h2><a name="write-a-short-note-on-trends-in-data-science-2022" class="heading-anchor" href="#write-a-short-note-on-trends-in-data-science-2022" rel="nofollow" aria-hidden="true"></a>Write a short note on Trends in Data Science. (2022)</h2>
<p>Data Science is a rapidly evolving field, with new trends emerging constantly. Some of the most significant trends include:</p>

<ol>
<li><strong>AI and Machine Learning Advancements</strong>

<ul>
<li><strong>Generative AI:</strong> Models like GPT-4 are revolutionizing content generation, from text to code.</li>
<li><strong>Reinforcement Learning:</strong> This technique is being applied to complex problems like autonomous vehicles and robotics.</li>
</ul></li>
<li><strong>Ethical AI and Data Privacy</strong>

<ul>
<li><strong>Data Privacy Regulations:</strong> Adhering to regulations like GDPR and CCPA.</li>
<li><strong>Responsible AI:</strong> Developing AI systems that are ethical and beneficial to society.</li>
</ul></li>
<li><strong>Edge Computing and IoT</strong>

<ul>
<li><strong>Real-time Analytics:</strong> Processing data at the edge devices to reduce latency.</li>
<li><strong>IoT Data Analysis:</strong> Extracting insights from vast amounts of IoT data.</li>
</ul></li>
<li><strong>Data Science Automation</strong>

<ul>
<li><strong>Low-code/No-code Tools:</strong> Empowering non-technical users to build data science models.</li>
</ul></li>
</ol>
<h1><a name="5-marks" class="heading-anchor" href="#5-marks" rel="nofollow" aria-hidden="true"></a>5 Marks</h1><h2><a name="define-defuzzification-and-state-the-necessity-of-the-defuzzification-process-2023-dec-2023-may" class="heading-anchor" href="#define-defuzzification-and-state-the-necessity-of-the-defuzzification-process-2023-dec-2023-may" rel="nofollow" aria-hidden="true"></a>Define defuzzification and state the necessity of the defuzzification process. (2023 Dec)  (2023 May)</h2>
<iframe src="https://www.youtube.com/embed/_po4FxxE9c8" title="Fuzzification and Defuzzification ll Soft Computing Course Explained in Hindi" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>Fuzzification and Defuzzification ll Soft Computing Course Explained in Hindi</iframe>

<p><img loading="lazy" src="assets/Pasted%20image%2020240828043056.png" alt="" /></p>

<p>Defuzzification is the inverse process of fuzzification, where the goal is to map a fuzzy set to a crisp set. This process is necessary because many applications require crisp control actions, and fuzzy results need to be converted into actionable, precise values.</p>

<p>There are several common defuzzification methods:</p>

<ul>
<li><strong>Centroid:</strong> The centroid method calculates the weighted average of the membership values of all elements in the fuzzy set.</li>
<li><strong>Mean of Maxima:</strong> This method selects the mean value of all elements with maximum membership values.</li>
<li><strong>Maximum Membership:</strong> This method simply selects the element with the highest membership value.</li>
<li><strong>Smallest of Maxima:</strong> This method selects the smallest element among those with maximum membership values.</li>
<li><strong>Largest of Maxima:</strong> This method selects the largest element among those with maximum membership values.</li>
</ul>

<p><strong>Necessity of Defuzzification:</strong></p>

<ul>
<li><strong>Real-world applications:</strong> Most real-world systems require crisp, numerical outputs.</li>
<li><strong>Human interaction:</strong> Humans generally prefer crisp, deterministic information.</li>
<li><strong>Integration with other systems:</strong> Many systems, especially legacy systems, are designed to work with crisp inputs and outputs.</li>
<li><strong>Decision making:</strong> Defuzzification is crucial for making final decisions based on fuzzy inputs. It provides a way to translate fuzzy information into a concrete action or choice.</li>
<li><strong>Efficiency:</strong> Defuzzification can improve the efficiency of fuzzy logic systems by converting fuzzy outputs into a format that is more easily processed by computers.</li>
</ul>
<h2><a name="describe-the-centroid-method-of-defuzzification-include-its-formula-and-discuss-its-advantages-and-disadvantages-compared-to-other-defuzzification-methods-2024-2022" class="heading-anchor" href="#describe-the-centroid-method-of-defuzzification-include-its-formula-and-discuss-its-advantages-and-disadvantages-compared-to-other-defuzzification-methods-2024-2022" rel="nofollow" aria-hidden="true"></a>Describe the Centroid method of defuzzification. Include its formula and discuss its advantages and disadvantages compared to other defuzzification methods. (2024) (2022)</h2>
<p>The centroid method of defuzzification, also known as the center of gravity or center of area method, is a widely used technique in fuzzy logic systems for converting a fuzzy output into a crisp value. This process is essential when making decisions based on fuzzy inputs, as it allows for clear, actionable results.</p>

<p><strong>Formula</strong></p>

<p>The centroid of a fuzzy set is calculated using the following formula:</p>

<p>$$C={∫_a^bx⋅​μ(x)dx \over ∫_a^b​μ(x)dx​}$$</p>

<p>Where:</p>

<ul>
<li>$C$ is the defuzzified output (the crisp value).</li>
<li>$μ(x)$ is the membership function of the fuzzy set.</li>
<li>$[a,b]$ represents the range over which the fuzzy set is defined.</li>
</ul>

<p><strong>Advantages:</strong></p>

<ul>
<li><strong>Simplicity:</strong> It's relatively easy to implement and understand.</li>
<li><strong>Smooth Output:</strong> The centroid method often produces smooth and continuous output values.</li>
<li><strong>Handles Multiple Peaks:</strong> It can handle membership functions with multiple peaks, unlike some other methods that might get confused.</li>
</ul>

<p><strong>Disadvantages:</strong></p>

<ul>
<li><strong>Sensitivity to Outliers:</strong> If the membership function has a long tail, the centroid can be significantly influenced by outliers.</li>
<li><strong>Computational Cost:</strong> For complex membership functions, calculating the integrals can be computationally expensive.</li>
<li><strong>Non-intuitive Results:</strong> In some cases, the centroid might not represent the most intuitive crisp value, especially for multimodal membership functions.</li>
</ul>

<p><strong>Comparison with Other Methods:</strong></p>

<ul>
<li><strong>Mean of Maxima (MOM):</strong>

<ul>
<li>Simpler to calculate but less sensitive to the shape of the membership function.</li>
<li>Can be less accurate, especially for multimodal functions.</li>
</ul></li>
<li><strong>Weighted Average:</strong>

<ul>
<li>Considers the weights of different fuzzy sets, making it more flexible.</li>
<li>Requires careful selection of weights.</li>
</ul></li>
<li><strong>Height Method:</strong>

<ul>
<li>Chooses the crisp value with the highest membership degree.</li>
<li>Can be less informative, especially when multiple peaks have similar heights.</li>
</ul></li>
</ul>
<h2><a name="compare-and-contrast-bagging-and-boosting-in-table-with-their-application-2024" class="heading-anchor" href="#compare-and-contrast-bagging-and-boosting-in-table-with-their-application-2024" rel="nofollow" aria-hidden="true"></a>Compare and contrast Bagging and Boosting in table with their application (2024)</h2>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Bagging</th>
<th>Boosting</th>
</tr>
</thead>

<tbody>
<tr>
<td><strong>Definition</strong></td>
<td>Trains multiple models independently.</td>
<td>Trains models sequentially to correct errors.</td>
</tr>

<tr>
<td><strong>Model Training</strong></td>
<td>Parallel training using random subsets.</td>
<td>Sequential training influenced by prior models.</td>
</tr>

<tr>
<td><strong>Base Learners</strong></td>
<td>Typically uses the same model type.</td>
<td>Often uses weaker models combined for strength.</td>
</tr>

<tr>
<td><strong>Error Handling</strong></td>
<td>Reduces variance; mitigates overfitting.</td>
<td>Reduces bias; improves accuracy.</td>
</tr>

<tr>
<td><strong>Overfitting</strong></td>
<td>Less prone due to averaging.</td>
<td>More prone if not regularized.</td>
</tr>

<tr>
<td><strong>Combination Method</strong></td>
<td>Majority voting or averaging.</td>
<td>Weighted sum based on model performance.</td>
</tr>

<tr>
<td><strong>Complexity</strong></td>
<td>Simpler and faster to implement.</td>
<td>More complex; requires careful tuning.</td>
</tr>

<tr>
<td><strong>Interpretability</strong></td>
<td>Easier to interpret.</td>
<td>Less interpretable due to complexity.</td>
</tr>
</tbody>
</table>

<p><strong>Applications</strong></p>

<table>
<thead>
<tr>
<th>Application</th>
<th>Bagging</th>
<th>Boosting</th>
</tr>
</thead>

<tbody>
<tr>
<td><strong>Healthcare</strong></td>
<td>Used for patient classification and risk assessment by averaging predictions from multiple models.</td>
<td>Applied for predicting disease outcomes based on complex patterns in patient data.</td>
</tr>

<tr>
<td><strong>Finance</strong></td>
<td>Employed in credit scoring models where variance reduction is critical.</td>
<td>Used in fraud detection systems to improve accuracy by focusing on misclassified transactions.</td>
</tr>

<tr>
<td><strong>Marketing</strong></td>
<td>Useful for customer segmentation by averaging predictions across multiple demographics.</td>
<td>Applied in churn prediction models to enhance targeting strategies by focusing on difficult-to-classify customers.</td>
</tr>

<tr>
<td><strong>Image Recognition</strong></td>
<td>Used in ensemble methods for object detection where stability is required.</td>
<td>Applied in tasks requiring high accuracy, such as facial recognition or scene understanding.</td>
</tr>
</tbody>
</table>
<h2><a name="what-is-the-significance-of-roc-curves-2023-dec" class="heading-anchor" href="#what-is-the-significance-of-roc-curves-2023-dec" rel="nofollow" aria-hidden="true"></a>What is the significance of ROC curves? (2023 Dec)</h2>
<p><img loading="lazy" src="assets/AUC-ROC-Curve.webp" alt="" /></p>

<p>A <strong>Receiver Operating Characteristic (ROC) curve</strong> is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. It's a powerful tool to visualize and assess the performance of classification models.</p>

<ol>
<li><strong>Performance Visualization</strong>:

<ul>
<li>ROC curves graphically show a model's ability to distinguish between classes at various thresholds.</li>
</ul></li>
<li><strong>True Positive vs. False Positive Rates</strong>:

<ul>
<li>They plot True Positive Rate (sensitivity) against False Positive Rate, illustrating the trade-off between sensitivity and specificity.</li>
</ul></li>
<li><strong>Model Comparison</strong>:

<ul>
<li>ROC curves allow for easy comparison of classifiers using the area under the curve (AUC); a higher AUC indicates better performance.</li>
</ul></li>
<li><strong>Threshold Selection</strong>:

<ul>
<li>Analyzing the curve helps in choosing an optimal classification threshold based on desired sensitivity and specificity.</li>
</ul></li>
<li><strong>Sensitivity to Improvements</strong>:

<ul>
<li>They highlight model performance improvements, showing how changes affect predictive capabilities.</li>
</ul></li>
</ol>
<h2><a name="various-metrics-for-evaluating-classifier-performance-2023-may" class="heading-anchor" href="#various-metrics-for-evaluating-classifier-performance-2023-may" rel="nofollow" aria-hidden="true"></a>Various metrics for evaluating classifier performance.  (2023 May)</h2>
<p>A confusion matrix is a table that summarizes the performance of a classification model on a set of test data. It provides a detailed breakdown of correct and incorrect predictions, categorized into four key metrics:  </p>

<ul>
<li><strong>True Positive (TP):</strong> Correctly predicted positive cases.</li>
<li><strong>True Negative (TN):</strong> Correctly predicted negative cases.</li>
<li><strong>False Positive (FP):</strong> Incorrectly predicted positive cases (Type I error).</li>
<li><strong>False Negative (FN):</strong> Incorrectly predicted negative cases (Type II error).</li>
</ul>

<p><img loading="lazy" src="assets/Pasted%20image%2020241102175357.png" alt="" /></p>

<p>Accuracy:</p>

<p>$${TP+TN \over P+N} = {100 + 50 \over Total} = {150 \over 165} = 0.90 = 90\%$$</p>

<p>Recall:</p>

<p>$${TP \over TP + FN} = {100 \over 100+5} = {100 \over 105} = 0.95 = 95\%$$</p>

<p>Specificity</p>

<p>$${TN \over N} = {50 \over 55} = 91\%$$</p>

<p>Precision</p>

<p>$${TP \over TP + FP} = {100 \over 100 + 10} = {100 \over 110} = 0.90 = 90.90\%$$</p>

<p>F1 Score</p>

<p>$$
{2 \times Precision \times Recall \over Precesion + Recall} =
{2 \times 0.90 \times 0.95 \over 0.90 + 0.95} =
{1.71 \over 1.85} = 0.9243 = 92.43\%
$$</p>

<p><img loading="lazy" src="../UT2/assets/Pasted%20image%2020241020231557.png" alt="" /></p>
<h2><a name="holdout-method-2023-may-2022" class="heading-anchor" href="#holdout-method-2023-may-2022" rel="nofollow" aria-hidden="true"></a>Holdout method (2023 May) (2022)</h2>
<p><strong>Holdout Method</strong> is a straightforward technique used to evaluate machine learning models. It involves splitting the dataset into two subsets:</p>

<ol>
<li><strong>Training Set:</strong> Used to train the model.</li>
<li><strong>Testing Set:</strong> Used to evaluate the model's performance on unseen data.</li>
</ol>

<p><strong>Process:</strong></p>

<ol>
<li><strong>Data Splitting:</strong> Divide the dataset into two parts, typically a 70-30 or 80-20 split.</li>
<li><strong>Model Training:</strong> Train the model on the training set.</li>
<li><strong>Model Evaluation:</strong> Evaluate the model's performance on the testing set using various metrics like accuracy, precision, recall, F1-score, etc.</li>
</ol>

<p><strong>Advantages:</strong></p>

<ul>
<li><strong>Simplicity:</strong> Easy to implement and understand.</li>
<li><strong>Quick:</strong> Relatively fast compared to other methods like cross-validation.</li>
</ul>

<p><strong>Disadvantages:</strong></p>

<ul>
<li><strong>Sensitivity to Data Split:</strong> The performance of the model can vary depending on how the data is split.</li>
<li><strong>Limited Data Utilization:</strong> A significant portion of the data is not used for training, which can lead to less accurate models, especially for smaller datasets.</li>
</ul>
<h2><a name="describe-the-random-subsampling-in-detail-2022" class="heading-anchor" href="#describe-the-random-subsampling-in-detail-2022" rel="nofollow" aria-hidden="true"></a>Describe the Random subsampling in detail. (2022)</h2>
<p>Random subsampling is a technique used in machine learning to evaluate the performance of a model on unseen data. It involves randomly splitting the dataset into two subsets: a training set and a testing set.</p>

<p><strong>Process:</strong></p>

<ol>
<li><strong>Random Split:</strong> The dataset is randomly divided into two subsets.  </li>
<li><strong>Model Training:</strong> The model is trained on the training set.</li>
<li><strong>Model Evaluation:</strong> The trained model is evaluated on the testing set.</li>
</ol>

<p><strong>Key Points:</strong></p>

<ul>
<li><strong>Randomness:</strong> The split is done randomly to ensure that the training and testing sets are representative of the overall dataset.</li>
<li><strong>Training and Testing Sets:</strong> The training set is used to train the model, while the testing set is used to evaluate its performance on unseen data.  </li>
<li><strong>Evaluation Metrics:</strong> Various metrics, such as accuracy, precision, recall, F1-score, and confusion matrix, are used to assess the model's performance.  </li>
</ul>

<p><strong>Advantages:</strong></p>

<ul>
<li><strong>Simplicity:</strong> It's a straightforward technique to implement.</li>
<li><strong>Flexibility:</strong> It can be used with different machine learning algorithms and datasets.</li>
</ul>

<p><strong>Disadvantages:</strong></p>

<ul>
<li><strong>Sensitivity to Data Split:</strong> The performance of the model can vary depending on how the data is split.  </li>
<li><strong>Limited Data Utilization:</strong> A significant portion of the data is not used for training, which can lead to less accurate models, especially for smaller datasets.</li>
</ul>
<h2><a name="lstm-2023-may" class="heading-anchor" href="#lstm-2023-may" rel="nofollow" aria-hidden="true"></a>LSTM (2023 May)</h2>
<p><strong>Long Short-Term Memory (LSTM)</strong> networks are a type of Recurrent Neural Network (RNN) specifically designed to address the vanishing gradient problem that plagues traditional RNNs.</p>

<p>Drawbacks of RNN:</p>

<ul>
<li>RNN goes in loop again and again which results in large update and loop may goes into infinity.</li>
<li>Values weight become too large and the result is overflow of data.</li>
</ul>

<p>Advantages of LSTM</p>

<ul>
<li><strong>Long-Range Dependencies</strong>: LSTMs can capture relationships over longer time steps, making them more effective than standard RNNs, which struggle with vanishing gradient problems.</li>
<li><strong>Flexibility</strong>: They can be applied to various types of sequential data, including text, audio, and time series.</li>
</ul>

<p>Application of LSTM:</p>

<ul>
<li>Speech Recognition</li>
<li>Machine Translation</li>
<li>Time Series Prediction</li>
<li>Healthcare Applications</li>
</ul>
<h2><a name="bayes-theorem-2023-may" class="heading-anchor" href="#bayes-theorem-2023-may" rel="nofollow" aria-hidden="true"></a>Bayes Theorem (2023 May)</h2>
<p>Bayes' Theorem is a fundamental principle in probability theory and statistics that describes how to update the probability of a hypothesis based on new evidence.</p>

<p><strong>Formula</strong></p>

<p>The theorem is expressed mathematically as:</p>

<p>$$P(H∣E)={P(E∣H)⋅P(H) \over P(E)}$$</p>

<p>Where:</p>

<ul>
<li>$P(H∣E)$: The posterior probability, or the probability of the hypothesis $H$ given the evidence $E$.</li>
<li>$P(E∣H)$: The likelihood, or the probability of observing evidence $E$ given that $H$ is true.</li>
<li>$P(H)$: The prior probability, or the initial probability of the hypothesis $H$ before observing the evidence.</li>
<li>$P(E)$: The marginal probability of the evidence $E$, which can be calculated using the law of total probability.</li>
</ul>
<h2><a name="application-of-data-science-for-text-2023-may" class="heading-anchor" href="#application-of-data-science-for-text-2023-may" rel="nofollow" aria-hidden="true"></a>Application of Data science for text (2023 May)</h2>
<ol>
<li><strong>Sentiment Analysis</strong>: Determines emotional tone in text (e.g., positive or negative).<br>
<em>Use Cases</em>: Brand monitoring, customer feedback.</li>
<li><strong>Text Classification</strong>: Assigns categories to documents based on content.<br>
<em>Use Cases</em>: Spam detection, topic categorization.</li>
<li><strong>Information Retrieval</strong>: Extracts relevant information from large datasets.<br>
<em>Use Cases</em>: Search engines, recommendation systems.</li>
<li><strong>Text Summarization</strong>: Creates concise summaries of longer documents.<br>
<em>Use Cases</em>: Summarizing news articles and reports.</li>
<li><strong>Machine Translation</strong>: Translates text between languages.<br>
<em>Use Cases</em>: Services like Google Translate.</li>
<li><strong>Chatbots and Virtual Assistants</strong>: Develops conversational agents for user interaction.
<em>Use Cases</em>: Customer service and personal assistants.</li>
<li><strong>Text Generation</strong>: Creates new text based on learned patterns.<br>
<em>Use Cases</em>: Automated content creation and report generation.</li>
</ol>
<h2><a name="describe-the-deep-learning-concept-with-an-example-2022" class="heading-anchor" href="#describe-the-deep-learning-concept-with-an-example-2022" rel="nofollow" aria-hidden="true"></a>Describe the Deep Learning concept with an example. (2022)</h2>
<p>Deep learning is a subset of machine learning that uses artificial neural networks with multiple layers (hence &quot;deep&quot;) to model complex patterns in data.</p>

<p>These networks are particularly powerful for tasks involving large amounts of unstructured data, such as images, audio, and text.</p>

<p><strong>Key Characteristics</strong></p>

<ol>
<li><strong>Neural Networks</strong>: Deep learning models are built using neural networks, which consist of interconnected nodes (neurons) organized in layers: an input layer, one or more hidden layers, and an output layer.</li>
<li><strong>Feature Learning</strong>: Unlike traditional machine learning methods that often require manual feature extraction, deep learning networks automatically learn features from the raw data. This ability enables them to capture intricate patterns.</li>
<li><strong>Large Datasets</strong>: Deep learning thrives on large datasets. The more data available, the better the model can learn and generalize.</li>
<li><strong>Backpropagation</strong>: This algorithm is used to update the weights of the network based on the error of the predictions, allowing the model to improve over time.</li>
</ol>

		</main>
        
        <details id="table-of-content">
           <summary>Table of Content</summary>
                    <nav>
<li><a href="#numerical">Numerical</a>
<ul>
<li><a href="#illustrate-inferencing-in-bayesian-belief-network-with-an-example-2023-dec-2022">
Illustrate inferencing in Bayesian Belief Network with an example. (2023 Dec) (2022)</a></li>
<li><a href="#find-p-cavity-toothache-from-the-given-probability-distribution-2023-dec-2022-5-marks">
Find P (¬ Cavity | Toothache) from the given probability distribution. (2023 Dec) (2022) 5 Marks</a></li>
<li><a href="#calculate-accuracy-precision-recall-sensitivity-and-specificity-for-the-given-confusion-matrix-2023-dec-2022-2024">
Calculate Accuracy, Precision, Recall, Sensitivity and Specificity for the given confusion matrix (2023 Dec) (2022) (2024)</a></li>
<li><a href="#implement-and-and-not-and-xor-function-using-mcculloch-pitts-neuron-2023-may-2023-dec-5-marks">
Implement AND, AND NOT and XOR function using McCulloch-Pitts neuron.  (2023 May) (2023 Dec 5 Marks)</a></li>
<li><a href="#using-mamdani-fuzzy-model-design-a-fuzzy-logic-controller-to-determine-the-wash-time-of-domestic-washing-machine-assume-the-inputs-are-dirt-and-grease-on-clothes-use-three-descriptors-for-each-input-variable-and-five-descriptor-for-output-variables-derive-necessary-membership-functions-and-required-fuzzy-rules-for-the-application-2024-2023-may">
Using Mamdani fuzzy model design a fuzzy logic controller to determine the wash time of domestic washing machine. Assume the inputs are dirt and grease on clothes. Use three descriptors for each input variable and five descriptor for output variables. Derive necessary membership functions and required fuzzy rules for the application. (2024) (2023 May)</a></li>
<li><a href="#find-the-algebraic-sum-algebraic-product-bounded-sum-and-bounded-difference-of-the-given-fuzzy-sets-2022">
Find the algebraic sum, algebraic product, bounded sum, and bounded difference of the given fuzzy sets. (2022)</a></li>
<li><a href="#from-a-standard-deck-of-playing-cards-a-single-card-is-drawn-the-probability-that-the-card-is-king-is-4-52-then-calculate-posterior-probability-p-king-face-which-means-the-drawn-face-card-is-a-king-card-2024-5-marks">
From a standard deck of playing cards, a single card is drawn. The probability that the card is king is 4/52, then calculate posterior probability P(King|Face), which means the drawn face card is a king card. (2024 5 Marks)</a></li>
</ul><li><a href="#10-marks">
10 Marks</a>
<ul>
<li><a href="#describe-the-architecture-of-a-typical-cnn-what-are-the-main-components-and-how-do-they-contribute-to-the-network-s-performance-in-image-recognition-tasks-2024-2023-dec-2022-2023-may-5-marks">
Describe the architecture of a typical CNN. What are the main components, and how do they contribute to the network's performance in image recognition tasks? (2024) (2023 Dec) (2022) (2023 May 5 Marks)</a></li>
<li><a href="#what-is-cognitive-computing-and-how-does-it-differ-from-traditional-computing-list-the-process-of-building-a-cognitive-application-2024-2023-dec-2023-may-2023-may-5-marks">
What is cognitive computing, and how does it differ from traditional computing? List the process of building a cognitive application. (2024) (2023 Dec) (2023 May) (2023 May 5 Marks)</a></li>
<li><a href="#explain-how-an-autoencoder-can-be-used-for-dimensionality-reduction-include-a-brief-description-of-how-the-encoder-and-decoder-parts-of-the-network-work-in-this-context-which-activation-function-is-best-for-an-autoencoder-2024-2023-may-2022">
Explain how an autoencoder can be used for dimensionality reduction. Include a brief description of how the encoder and decoder parts of the network work in this context. Which activation function is best for an autoencoder?  (2024) (2023 May) (2022)</a></li>
<li><a href="#briefly-explain-data-science-for-multimodal-applications-2024-2023-may-2022">
Briefly explain Data science for Multimodal applications. (2024) (2023 May) (2022)</a></li>
<li><a href="#how-do-you-explain-random-forest-does-random-forest-need-pruning-explain-in-detail-2024-2023-may">
How do you explain random forest? Does random forest need pruning, explain in detail? (2024) (2023 May)</a></li>
<li><a href="#describe-how-cognitive-computing-can-be-applied-in-healthcare-provide-specific-examples-of-tasks-or-problems-that-cognitive-computing-can-help-address-and-explain-the-potential-benefits-2024-2022">
Describe how cognitive computing can be applied in healthcare. Provide specific examples of tasks or problems that cognitive computing can help address, and explain the potential benefits. (2024) (2022)</a></li>
<li><a href="#what-is-a-markov-decision-process-mdp-list-its-primary-components-explain-in-detail-2024-2023-may">
What is a Markov Decision Process (MDP)? List its primary components. Explain in detail. (2024)  (2023 May)</a></li>
<li><a href="#how-does-class-imbalance-affect-classification-what-are-the-ways-to-solve-class-imbalanced-problems-2023-may-2022">
How does class imbalance affect classification? What are the ways to solve class imbalanced problems?  (2023 May) (2022)</a></li>
<li><a href="#state-and-elaborate-the-applications-of-deep-learning-2023-dec-2024-5-marks">
State and elaborate the applications of deep learning. (2023 Dec)  (2024 5 Marks)</a></li>
<li><a href="#list-three-industries-where-data-science-is-extensively-used-and-briefly-describe-one-application-in-each-industry-2024">
List three industries where data science is extensively used and briefly describe one application in each industry. (2024)</a></li>
<li><a href="#state-ensemble-methods-and-describe-any-one-2023-dec">
State Ensemble methods and describe any one. (2023 Dec)</a></li>
<li><a href="#illustrate-usage-of-taxonomies-and-ontologies-for-knowledge-representation-in-cognitive-systems-2023-dec">
Illustrate usage of taxonomies and ontologies for knowledge representation in cognitive systems. (2023 Dec)</a></li>
<li><a href="#perform-a-case-study-on-a-book-recommendation-system-data-science-based-2023-dec">
Perform a case study on a book recommendation system (data science based). (2023 Dec)</a></li>
<li><a href="#describe-the-properties-of-fuzzy-sets-with-an-example-2023-dec">
Describe the properties of Fuzzy Sets with an example. (2023 Dec)</a></li>
<li><a href="#define-cognitive-computing-and-draw-a-diagram-of-the-elements-of-a-cognitive-system-explaining-each-element-2022">
Define Cognitive Computing and draw a diagram of the elements of a cognitive system, explaining each element. (2022)</a></li>
<li><a href="#write-a-short-note-on-trends-in-data-science-2022">
Write a short note on Trends in Data Science. (2022)</a></li>
</ul><li><a href="#5-marks">
5 Marks</a>
<ul>
<li><a href="#define-defuzzification-and-state-the-necessity-of-the-defuzzification-process-2023-dec-2023-may">
Define defuzzification and state the necessity of the defuzzification process. (2023 Dec)  (2023 May)</a></li>
<li><a href="#describe-the-centroid-method-of-defuzzification-include-its-formula-and-discuss-its-advantages-and-disadvantages-compared-to-other-defuzzification-methods-2024-2022">
Describe the Centroid method of defuzzification. Include its formula and discuss its advantages and disadvantages compared to other defuzzification methods. (2024) (2022)</a></li>
<li><a href="#compare-and-contrast-bagging-and-boosting-in-table-with-their-application-2024">
Compare and contrast Bagging and Boosting in table with their application (2024)</a></li>
<li><a href="#what-is-the-significance-of-roc-curves-2023-dec">
What is the significance of ROC curves? (2023 Dec)</a></li>
<li><a href="#various-metrics-for-evaluating-classifier-performance-2023-may">
Various metrics for evaluating classifier performance.  (2023 May)</a></li>
<li><a href="#holdout-method-2023-may-2022">
Holdout method (2023 May) (2022)</a></li>
<li><a href="#describe-the-random-subsampling-in-detail-2022">
Describe the Random subsampling in detail. (2022)</a></li>
<li><a href="#lstm-2023-may">
LSTM (2023 May)</a></li>
<li><a href="#bayes-theorem-2023-may">
Bayes Theorem (2023 May)</a></li>
<li><a href="#application-of-data-science-for-text-2023-may">
Application of Data science for text (2023 May)</a></li>
<li><a href="#describe-the-deep-learning-concept-with-an-example-2022">
Describe the Deep Learning concept with an example. (2022)</a></li>
</ul>
</nav>

        </details>
        
		<footer>
			<p style="text-align: center; font-size: small; margin-top: 5em;">
                <a href="https://anzenkodo.github.io/license">LICENSE</a>
            </p>
		</footer>
	</body>
    <script async src="https://AnzenKodo.github.io/assets/js/mermaid.js"></script>
	<script id="MathJax-script" async src="https://AnzenKodo.github.io/assets/js/mathjax.js"></script>
    <script>
		const audio = document.querySelector('audio');
		const image = document.getElementById('audio-img').addEventListener('click', () => {
		     if (audio.paused) {
		         audio.play();
		     } else {
		         audio.pause();
		     }
		});

        mermaid.initialize({
            theme: "neutral"
        });

        MathJax = {
		  tex: {
		    inlineMath: [['$', '$']],
		    displayMath: [['$$', '$$']],
		  }
		};
    </script>
</html>
